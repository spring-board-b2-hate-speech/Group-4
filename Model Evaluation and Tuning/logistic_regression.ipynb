{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "057979bf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "057979bf",
        "outputId": "81bcdd7f-874c-4d7b-f288-8c92c9dd87f8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14622    ['there', 'new', 'shop', 'block', 'with', 'the...\n",
              "5049                                ['fag', 'are', 'evil']\n",
              "7386                               ['jizz', 'for', 'jazz']\n",
              "11513    ['data', 'show', 'different', 'trend', 'for', ...\n",
              "7765                      ['you', 'lying', 'sack', 'shit']\n",
              "                               ...                        \n",
              "11284    ['people', 'who', 'take', 'time', 'out', 'thei...\n",
              "11964                         ['fucking', 'hate', 'house']\n",
              "5390        ['ssssssshhhhhhhooooot', 'the', 'bllllllakkk']\n",
              "860                         ['nigger', 'are', 'redundant']\n",
              "15795             ['this', 'computer', 'utter', 'rubbish']\n",
              "Name: Tokens, Length: 14076, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "data = pd.read_csv(\"Tokenized_HateSpeechDetection.csv\")\n",
        "X=data['Tokens']\n",
        "y=data['Label']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "X_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "2cf7047c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2cf7047c",
        "outputId": "c9ffdfa3-1ed8-43ed-b125-e2488f4d2072"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.word2vec:Each 'sentences' item should be a list of words (usually unicode strings). First item here is instead plain <class 'str'>.\n",
            "WARNING:gensim.models.word2vec:Each 'sentences' item should be a list of words (usually unicode strings). First item here is instead plain <class 'str'>.\n"
          ]
        }
      ],
      "source": [
        "from gensim.models import Word2Vec\n",
        "import numpy as np\n",
        "def word2vec_embedding_sg(texts):\n",
        "    model = Word2Vec(sentences=X_train, vector_size=200, window=6, min_count=1, workers=4,sg=1)\n",
        "    word_vectors = model.wv\n",
        "    #print(word_vectors)\n",
        "\n",
        "    def get_word2vec_embeddings(text, word_vectors):\n",
        "        embeddings = [word_vectors[word] for word in text if word in word_vectors]\n",
        "        if embeddings:\n",
        "            return np.mean(embeddings, axis=0)\n",
        "        else:\n",
        "            return np.zeros(200)\n",
        "\n",
        "    embeddings = np.array([get_word2vec_embeddings(text, word_vectors) for text in texts])\n",
        "    return embeddings\n",
        "X_train_w2v=word2vec_embedding_sg(X_train)\n",
        "X_test_w2v=word2vec_embedding_sg(X_test)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e86a6c5a",
      "metadata": {
        "id": "e86a6c5a"
      },
      "source": [
        "# Logistic Regression Model:\n",
        "Logistic regression is a statistical model used for binary classification tasks. It estimates the probability that a given input belongs to a certain class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "00c9282b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "00c9282b",
        "outputId": "7c767c21-9aed-4106-f0a8-954256f6e508"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression\n",
            "Precision: 1.0\n",
            "Recall: 0.001402524544179523\n",
            "Accuracy: 0.7454545454545455\n",
            "ROC-AUC Score: 0.7007012622720898\n",
            "f1: 0.0028011204481792717\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, roc_auc_score\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, roc_auc_score\n",
        "\n",
        "# Train a Logistic Regression model\n",
        "lr_clf = LogisticRegression()\n",
        "lr_clf.fit(X_train_w2v, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = lr_clf.predict(X_test_w2v)\n",
        "\n",
        "# Evaluate the classifier\n",
        "print(\"Logistic Regression\")\n",
        "# Precision\n",
        "precision = precision_score(y_test, y_pred)\n",
        "print(\"Precision:\", precision)\n",
        "\n",
        "# Recall\n",
        "recall = recall_score(y_test, y_pred)\n",
        "print(\"Recall:\", recall)\n",
        "\n",
        "\n",
        "# Accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "# ROC-AUC\n",
        "roc_auc = roc_auc_score(y_test, y_pred)\n",
        "print(\"ROC-AUC Score:\", roc_auc)\n",
        "\n",
        "#f1_score\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "print(\"f1:\", f1)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "2e98fd6f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2e98fd6f",
        "outputId": "2050925a-d1e7-4429-dcb4-aea4b1a9737a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
            "30 fits failed out of a total of 120.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "30 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.59690253        nan 0.59690253 0.59690253 0.59690253        nan\n",
            " 0.59690253 0.59690253 0.59690253        nan 0.59690253 0.59690253\n",
            " 0.59690253        nan 0.59690253 0.59690253 0.59676046        nan\n",
            " 0.59690253 0.59690253 0.60073896        nan 0.59839433 0.59839433]\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Logistic Regression using Grid Search\n",
            "Precision: 0.5986037234042554\n",
            "f1: 0.7408209291835814\n",
            "Accuracy: 0.821590909090909\n",
            "ROC-AUC Score: 0.6884583080490441\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Define the hyperparameter grid\n",
        "param_grid = {\n",
        "    'penalty': ['l1', 'l2'],\n",
        "    'C': [0.01, 0.05, 0.1, 0.5, 1.0, 10.0],\n",
        "    'solver': ['liblinear', 'lbfgs']\n",
        "}\n",
        "\n",
        "# Initialize GridSearchCV\n",
        "grid_search = GridSearchCV(LogisticRegression(), param_grid, cv=5, scoring='accuracy')\n",
        "\n",
        "# Fit the model\n",
        "grid_search.fit(X_train_w2v, y_train)\n",
        "\n",
        "# Get the best model\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "# Make predictions\n",
        "y_pred = best_model.predict(X_test_w2v)\n",
        "\n",
        "# Evaluate the classifier\n",
        "print(\"Best Logistic Regression using Grid Search\")\n",
        "print(\"Precision:\", precision_score(y_test, y_pred))\n",
        "print(\"f1:\", f1_score(y_test, y_pred))\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"ROC-AUC Score:\", roc_auc_score(y_test, y_pred))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "480988bb",
      "metadata": {
        "id": "480988bb"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}