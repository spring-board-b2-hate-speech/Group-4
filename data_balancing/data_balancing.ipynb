{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import re\n",
    "\n",
    "# Assume train_data is already loaded into a pandas DataFrame\n",
    "# train_data = pd.read_csv('path_to_your_csv.csv')\n",
    "\n",
    "# Preprocess text data: Remove NaNs, clean text, and split data\n",
    "train_data = train_data.dropna(subset=['text', 'label'])\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    text = re.sub(r'@\\w+', '', text)\n",
    "    text = re.sub(r'#\\w+', '', text)\n",
    "    text = re.sub(r'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Load your DataFrame (df)\n",
    "# df = pd.read_csv('path_to_your_csv.csv')\n",
    "\n",
    "# Count the number of columns in the DataFrame\n",
    "column_count = df.shape[1]\n",
    "print(f\"Number of columns: {column_count}\")\n",
    "\n",
    "# Function to preprocess text\n",
    "def preprocess_text(text):\n",
    "    # Remove special characters and numbers\n",
    "    cleaned_text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    # Convert to lowercase\n",
    "    cleaned_text = cleaned_text.lower()\n",
    "    return cleaned_text\n",
    "\n",
    "# Apply preprocessing to the 'comment' column\n",
    "df['processed_comment'] = df['comment'].apply(preprocess_text)\n",
    "\n",
    "# Split the dataset into features (X) and target (y)\n",
    "X = df['processed_comment']\n",
    "y = df['label']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Vectorize the text data (convert text to numerical features)\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=1000)  # Adjust max_features as needed\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(X)\n",
    "\n",
    "# Print the shape of the data before sampling\n",
    "print(f\"Shape of data before sampling: {X_tfidf.shape}, {y.shape}\")\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train_tfidf, X_test_tfidf, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import re\n",
    "\n",
    "# Load your DataFrame (df)\n",
    "# df = pd.read_csv('path_to_your_csv.csv')\n",
    "\n",
    "# Count the number of columns in the DataFrame\n",
    "column_count = df.shape[1]\n",
    "print(f\"Number of columns: {column_count}\")\n",
    "\n",
    "# Function to preprocess text\n",
    "def preprocess_text(text):\n",
    "    # Remove special characters and numbers\n",
    "    cleaned_text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    # Convert to lowercase\n",
    "    cleaned_text = cleaned_text.lower()\n",
    "    return cleaned_text\n",
    "\n",
    "# Apply preprocessing to the 'comment' column\n",
    "df['processed_comment'] = df['comment'].apply(preprocess_text)\n",
    "\n",
    "# Split the dataset into features (X) and target (y)\n",
    "X = df['processed_comment']\n",
    "y = df['label']\n",
    "\n",
    "# Vectorize the text data (convert text to numerical features)\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=1000)  # Adjust max_features as needed\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(X)\n",
    "\n",
    "# Print the shape of the data before sampling\n",
    "print(f\"Shape of data before sampling: {X_tfidf.shape}, {y.shape}\")\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train_tfidf, X_test_tfidf, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Handle class imbalance using RandomOverSampler\n",
    "oversampler = RandomOverSampler(random_state=42)\n",
    "X_resampled, y_resampled = oversampler.fit_resample(X_train_tfidf, y_train)\n",
    "\n",
    "# Train a K-Nearest Neighbors classifier\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_classifier.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = knn_classifier.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate the model after random oversampling\n",
    "print(\"Evaluation after Random Oversampling:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
