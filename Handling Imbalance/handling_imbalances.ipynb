{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "057979bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\balui\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\balui\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\balui\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 Text  Label\n",
      "0   Damn I thought they had strict gun laws in Ger...      0\n",
      "1   I dont care about what it stands for or anythi...      0\n",
      "2                   It's not a group it's an idea lol      0\n",
      "3                           So it's not just America!      0\n",
      "4   The dog is a spectacular dancer considering he...      0\n",
      "5   If ppl dont wear masks you complain... If ppl ...      0\n",
      "6             We should send them All back  to africa      1\n",
      "7   Checking to see if it's whataboutism from the ...      0\n",
      "8                      As a european, I approve this.      0\n",
      "9   Idk which of these groups to join, they're all...      0\n",
      "10  Sometimes the messenger is just as important a...      0\n",
      "11                    This is the future we all want.      0\n",
      "12     Wow the monkey calls someone else a monkey lol      1\n",
      "13                   They are the gypsies of America.      1\n",
      "14                                   I know that guy!      0\n",
      "                                                    Text  Label\n",
      "17586  africans should be in a zoo with the other ani...      1\n",
      "17587       I wouldn't want my daughter to marry a Chink      1\n",
      "17588  not anymore. they are like the shitty utube no...      1\n",
      "17589  Yet still, better for a 750cc to seek a win (o...      0\n",
      "17590  people this is new thread due to the impending...      0\n",
      "17591    I find rats nicer and cleaner than most Chinese      1\n",
      "17592  Check out this niggar, they hit things like wi...      1\n",
      "17593  this country has become an absolute shambles, ...      0\n",
      "17594  Me aged 16 = anti-Semitism is bad Me aged 18 =...      1\n",
      "17595    so messed up saying blacks don't deserve rights      0\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17596 entries, 0 to 17595\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Text    17596 non-null  object\n",
      " 1   Label   17596 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 275.1+ KB\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import contractions\n",
    "import numpy as np\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "data = pd.read_csv(\"HateSpeechDetection.csv\")\n",
    "print(data.head(15))\n",
    "print(data.tail(10))\n",
    "print(data.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2639c66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_cleaning(data):\n",
    "    def remove_extra_spaces(text):\n",
    "        return re.sub(r'\\s+', ' ', text) #the re.sub function replaces one or more whitespace characters (\\s+) with a single space.\n",
    "\n",
    "    def remove_username(text):\n",
    "        return re.sub(r\"@\\S+\", \"\",text) \n",
    "    #We used pattern “@\\S+” -> it suggests string group which starts with ‘@’ and followed by non-whitespace character(\\S), ‘+’ means repeatition of preceding character one or more times\n",
    "\n",
    "    def remove_hashtags(text):\n",
    "        return re.sub(r'#', '', text)\n",
    "    # replacing the character(\"#\") with \"\" but not removing the term.\n",
    "    \n",
    "    \n",
    "    def text_lower(text):\n",
    "        return text.lower()\n",
    "    \n",
    "    def remove_punctuation(text):\n",
    "        return re.sub(r'[^\\w\\s]', '', text)\n",
    "    #\\w: Represents any alphanumeric character (equivalent to [a-zA-Z0-9_]).\n",
    "    #\\s: Denotes any whitespace character, such as space, tab, or newline.\n",
    "    # so it defines the other than a alphanumeric character followed by a single space, ('^' for negation) remove other characters\n",
    "\n",
    "    def remove_url(text):\n",
    "        return re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
    "    # it identifies the words starting with http or https or www and ending with a non-white space Character(\\S) then remove it\n",
    "\n",
    "    \n",
    "    def lemmatizers(text):\n",
    "        text = nltk.word_tokenize(text)\n",
    "        word=[]\n",
    "        for i in text:\n",
    "            if i not in stopwords.words('english'):\n",
    "                word.append(lemmatizer.lemmatize(i))\n",
    "            else:\n",
    "                word.append(i)\n",
    "        return ' '.join(word)\n",
    "\n",
    "    data['Text'] = data['Text'].apply(remove_extra_spaces)\n",
    "\n",
    "    data['Text'] = data['Text'].apply(remove_username)\n",
    "\n",
    "    data['Text'] = data['Text'].apply(remove_hashtags)\n",
    "\n",
    "    data['Text']=data['Text'].apply(lambda x:contractions.fix(x))\n",
    "    \n",
    "    data['Text'] = data['Text'].apply(text_lower)\n",
    "    \n",
    "    data['Text'] = data['Text'].apply(remove_punctuation)\n",
    "\n",
    "    data['Text'] = data['Text'].apply(remove_url)\n",
    "    \n",
    "    data['Text'] = data['Text'].apply(lambda x: ' '.join([word for word in x.split() if len(word) >= 3 or word.isnumeric()]))\n",
    "    \n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    data['Text'] = data['Text'].apply(lemmatizers)\n",
    "    \n",
    "    return data\n",
    "cleaned_data=data_cleaning(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c59a9dc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>damn thought they had strict gun law germany</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>not care about what stand for anything its con...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>not group idea lol</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>not just america</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the dog spectacular dancer considering has two...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17591</th>\n",
       "      <td>find rat nicer and cleaner than most chinese</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17592</th>\n",
       "      <td>check out this niggar they hit thing like wild...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17593</th>\n",
       "      <td>this country has become absolute shamble the a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17594</th>\n",
       "      <td>aged 16 antisemitism bad aged 18 antisemitism ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17595</th>\n",
       "      <td>messed saying black not deserve right</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17596 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Text  Label\n",
       "0           damn thought they had strict gun law germany      0\n",
       "1      not care about what stand for anything its con...      0\n",
       "2                                     not group idea lol      0\n",
       "3                                       not just america      0\n",
       "4      the dog spectacular dancer considering has two...      0\n",
       "...                                                  ...    ...\n",
       "17591       find rat nicer and cleaner than most chinese      1\n",
       "17592  check out this niggar they hit thing like wild...      1\n",
       "17593  this country has become absolute shamble the a...      0\n",
       "17594  aged 16 antisemitism bad aged 18 antisemitism ...      1\n",
       "17595              messed saying black not deserve right      0\n",
       "\n",
       "[17596 rows x 2 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0cc30431",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "def tokenization(data):\n",
    "    data['Tokens']=data['Text'].apply(word_tokenize)\n",
    "    return data\n",
    "tokenized_data=tokenization(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "62cf16a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "      <th>Tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>damn thought they had strict gun law germany</td>\n",
       "      <td>0</td>\n",
       "      <td>[damn, thought, they, had, strict, gun, law, g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>not care about what stand for anything its con...</td>\n",
       "      <td>0</td>\n",
       "      <td>[not, care, about, what, stand, for, anything,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>not group idea lol</td>\n",
       "      <td>0</td>\n",
       "      <td>[not, group, idea, lol]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>not just america</td>\n",
       "      <td>0</td>\n",
       "      <td>[not, just, america]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the dog spectacular dancer considering has two...</td>\n",
       "      <td>0</td>\n",
       "      <td>[the, dog, spectacular, dancer, considering, h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17591</th>\n",
       "      <td>find rat nicer and cleaner than most chinese</td>\n",
       "      <td>1</td>\n",
       "      <td>[find, rat, nicer, and, cleaner, than, most, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17592</th>\n",
       "      <td>check out this niggar they hit thing like wild...</td>\n",
       "      <td>1</td>\n",
       "      <td>[check, out, this, niggar, they, hit, thing, l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17593</th>\n",
       "      <td>this country has become absolute shamble the a...</td>\n",
       "      <td>0</td>\n",
       "      <td>[this, country, has, become, absolute, shamble...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17594</th>\n",
       "      <td>aged 16 antisemitism bad aged 18 antisemitism ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[aged, 16, antisemitism, bad, aged, 18, antise...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17595</th>\n",
       "      <td>messed saying black not deserve right</td>\n",
       "      <td>0</td>\n",
       "      <td>[messed, saying, black, not, deserve, right]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17596 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Text  Label  \\\n",
       "0           damn thought they had strict gun law germany      0   \n",
       "1      not care about what stand for anything its con...      0   \n",
       "2                                     not group idea lol      0   \n",
       "3                                       not just america      0   \n",
       "4      the dog spectacular dancer considering has two...      0   \n",
       "...                                                  ...    ...   \n",
       "17591       find rat nicer and cleaner than most chinese      1   \n",
       "17592  check out this niggar they hit thing like wild...      1   \n",
       "17593  this country has become absolute shamble the a...      0   \n",
       "17594  aged 16 antisemitism bad aged 18 antisemitism ...      1   \n",
       "17595              messed saying black not deserve right      0   \n",
       "\n",
       "                                                  Tokens  \n",
       "0      [damn, thought, they, had, strict, gun, law, g...  \n",
       "1      [not, care, about, what, stand, for, anything,...  \n",
       "2                                [not, group, idea, lol]  \n",
       "3                                   [not, just, america]  \n",
       "4      [the, dog, spectacular, dancer, considering, h...  \n",
       "...                                                  ...  \n",
       "17591  [find, rat, nicer, and, cleaner, than, most, c...  \n",
       "17592  [check, out, this, niggar, they, hit, thing, l...  \n",
       "17593  [this, country, has, become, absolute, shamble...  \n",
       "17594  [aged, 16, antisemitism, bad, aged, 18, antise...  \n",
       "17595       [messed, saying, black, not, deserve, right]  \n",
       "\n",
       "[17596 rows x 3 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3757241b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "def word2vec_embedding_sg(texts):\n",
    "    model = Word2Vec(texts, vector_size=200, window=6, min_count=1, workers=4,sg=1)\n",
    "    word_vectors = model.wv\n",
    "    #print(word_vectors)\n",
    "\n",
    "    def get_word2vec_embeddings(text, word_vectors):\n",
    "        embeddings = [word_vectors[word] for word in text if word in word_vectors]\n",
    "        if embeddings:\n",
    "            return np.mean(embeddings, axis=0)\n",
    "        else:\n",
    "            return np.zeros(200)\n",
    "\n",
    "    embeddings = np.array([get_word2vec_embeddings(text, word_vectors) for text in texts])\n",
    "    return embeddings\n",
    "\n",
    "embeddings_w2v_sg = word2vec_embedding_sg(tokenized_data['Tokens'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "57dee0da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    8402\n",
      "1    5674\n",
      "Name: Label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "X_train, X_test, y_train, y_test = train_test_split(embeddings_w2v_sg, data['Label'], test_size=0.2, random_state=42)\n",
    "\n",
    "print(y_train.value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878ab089",
   "metadata": {},
   "source": [
    "# Imbalanced data:\n",
    "From the above output, we can observe that after splitting dataset into training and test data, there is an imbalance in 'Label' column in the training data as we can see there are 8402 instances of label '0' where as there are only 5674 instances of label '1'. This would significantly effect model training because models trained on this dataset might be biased towards the majority class (non-hate speech) and may not perform as well in identifying hate speech instances.\n",
    "\n",
    "The training data can be balanced using resampling techniques like undersampling and oversampling.\n",
    "\n",
    "we can randomly delete rows from the majority class to match them with the minority class which is called undersampling.\n",
    "\n",
    "When we are using an imbalanced dataset, we can oversample the minority class using replacement. This technique used to handle imbalanced data is called oversampling.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "905b9f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "#create two different dataframe of majority and minority class\n",
    "df_train = pd.DataFrame(X_train, y_train)\n",
    "#print(df_train.info())\n",
    "df_majority = df_train[df_train.index == 0]\n",
    "df_minority = df_train[df_train.index == 1]\n",
    "# upsample minority class\n",
    "df_minority_upsampled = resample(data_minority, \n",
    "                                 replace=True,\n",
    "                                 n_samples= 8402,    # sample with replacement\n",
    "                                 random_state=42)\n",
    "\n",
    "df_upsampled = pd.concat([df_minority_upsampled, df_majority])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b74010d",
   "metadata": {},
   "source": [
    "But generally, a random oversampler is not preferably used because it duplicates the minority instances to equalize with majority instances."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf924cec",
   "metadata": {},
   "source": [
    "# SMOTE:\n",
    " Synthetic Minority Oversampling Technique or SMOTE, which is another technique to oversample the minority class. Simply adding duplicate records of minority class often don’t adon’ty new information to the model. In SMOTE new instances are synthesized from the existing data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "81013400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    8402\n",
      "0    8402\n",
      "Name: Label, dtype: int64\n",
      "Original dataset shape: (14076, 200)\n",
      "Resampled dataset shape: (16804, 200)\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "print(y_train_resampled.value_counts())\n",
    "print(\"Original dataset shape:\", X_train.shape)\n",
    "print(\"Resampled dataset shape:\", X_train_resampled.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
