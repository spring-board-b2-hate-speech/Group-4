{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c2b53a9",
   "metadata": {},
   "source": [
    "Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9112579b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "data  = pd.read_csv(\"dataset.csv\")\n",
    "import nltk\n",
    "nltk.download('punkt') \n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "data['Tokens']=data['Text'].apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1997f79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nltk.tokenize import TreebankWordTokenizer\n",
    "\n",
    "# def rule_based_tokenize(text):\n",
    "#     tokenizer = TreebankWordTokenizer()\n",
    "#     return tokenizer.tokenize(text)\n",
    "\n",
    "# data['token_rbt']=data['Text'].apply(rule_based_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a1687b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import GPT2Tokenizer\n",
    "\n",
    "# def bpe_tokenize(text):\n",
    "#     tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "#     return tokenizer.tokenize(text)\n",
    "# data['token_bpe']=data['Text'].apply(rule_based_tokenize)\n",
    "# data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d27b3fd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17596 entries, 0 to 17595\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Text    17596 non-null  object\n",
      " 1   Label   17596 non-null  int64 \n",
      " 2   Tokens  17596 non-null  object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 412.5+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "412abfda",
   "metadata": {},
   "source": [
    "Embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c7409421",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = data['Text'].values\n",
    "labels = data['Label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fc10831f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Compressed Sparse Row sparse matrix of dtype 'int64'\n",
      "\twith 320602 stored elements and shape (17596, 20763)>\n",
      "  Coords\tValues\n",
      "  (0, 4634)\t1\n",
      "  (0, 18506)\t1\n",
      "  (0, 18453)\t1\n",
      "  (0, 8227)\t1\n",
      "  (0, 17690)\t1\n",
      "  (0, 8173)\t1\n",
      "  (0, 10461)\t1\n",
      "  (0, 9215)\t1\n",
      "  (0, 7736)\t1\n",
      "  (1, 5579)\t1\n",
      "  (1, 2972)\t1\n",
      "  (1, 394)\t1\n",
      "  (1, 20131)\t1\n",
      "  (1, 9788)\t1\n",
      "  (1, 17485)\t1\n",
      "  (1, 7220)\t1\n",
      "  (1, 13004)\t1\n",
      "  (1, 1096)\t1\n",
      "  (1, 9800)\t1\n",
      "  (1, 3977)\t1\n",
      "  (1, 18653)\t1\n",
      "  (1, 10719)\t1\n",
      "  (1, 18404)\t1\n",
      "  (1, 16541)\t1\n",
      "  (2, 9788)\t1\n",
      "  :\t:\n",
      "  (17594, 6498)\t1\n",
      "  (17594, 123)\t1\n",
      "  (17594, 53)\t1\n",
      "  (17594, 6298)\t1\n",
      "  (17594, 3914)\t1\n",
      "  (17594, 15001)\t1\n",
      "  (17594, 17530)\t1\n",
      "  (17594, 16061)\t1\n",
      "  (17594, 9902)\t1\n",
      "  (17594, 1058)\t1\n",
      "  (17594, 697)\t1\n",
      "  (17594, 68)\t1\n",
      "  (17594, 12285)\t1\n",
      "  (17594, 16320)\t1\n",
      "  (17594, 1074)\t1\n",
      "  (17594, 15570)\t1\n",
      "  (17594, 11487)\t1\n",
      "  (17595, 17055)\t1\n",
      "  (17595, 19474)\t1\n",
      "  (17595, 5562)\t1\n",
      "  (17595, 2188)\t1\n",
      "  (17595, 5030)\t1\n",
      "  (17595, 16061)\t1\n",
      "  (17595, 11517)\t1\n",
      "  (17595, 15632)\t1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "def one_hot_encoding(texts):\n",
    "    vectorizer = CountVectorizer(binary=True)\n",
    "    embeddings = vectorizer.fit_transform(texts)\n",
    "    return embeddings\n",
    "\n",
    "embeddings_one_hot = one_hot_encoding(texts)\n",
    "X_train_one_hot, X_test_one_hot, y_train_one_hot, y_test_one_hot = train_test_split(embeddings_one_hot, labels, test_size=0.2, random_state=42)\n",
    "print(embeddings_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a6c480f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Compressed Sparse Row sparse matrix of dtype 'int64'\n",
      "\twith 320602 stored elements and shape (17596, 20763)>\n",
      "  Coords\tValues\n",
      "  (0, 4634)\t1\n",
      "  (0, 18506)\t1\n",
      "  (0, 18453)\t1\n",
      "  (0, 8227)\t1\n",
      "  (0, 17690)\t1\n",
      "  (0, 8173)\t1\n",
      "  (0, 10461)\t1\n",
      "  (0, 9215)\t1\n",
      "  (0, 7736)\t1\n",
      "  (1, 5579)\t1\n",
      "  (1, 2972)\t1\n",
      "  (1, 394)\t1\n",
      "  (1, 20131)\t1\n",
      "  (1, 9788)\t1\n",
      "  (1, 17485)\t1\n",
      "  (1, 7220)\t1\n",
      "  (1, 13004)\t1\n",
      "  (1, 1096)\t1\n",
      "  (1, 9800)\t1\n",
      "  (1, 3977)\t1\n",
      "  (1, 18653)\t1\n",
      "  (1, 10719)\t1\n",
      "  (1, 18404)\t1\n",
      "  (1, 16541)\t1\n",
      "  (2, 9788)\t2\n",
      "  :\t:\n",
      "  (17594, 6498)\t1\n",
      "  (17594, 123)\t1\n",
      "  (17594, 53)\t1\n",
      "  (17594, 6298)\t1\n",
      "  (17594, 3914)\t1\n",
      "  (17594, 15001)\t1\n",
      "  (17594, 17530)\t1\n",
      "  (17594, 16061)\t1\n",
      "  (17594, 9902)\t1\n",
      "  (17594, 1058)\t3\n",
      "  (17594, 697)\t3\n",
      "  (17594, 68)\t1\n",
      "  (17594, 12285)\t1\n",
      "  (17594, 16320)\t3\n",
      "  (17594, 1074)\t1\n",
      "  (17594, 15570)\t1\n",
      "  (17594, 11487)\t1\n",
      "  (17595, 17055)\t1\n",
      "  (17595, 19474)\t1\n",
      "  (17595, 5562)\t1\n",
      "  (17595, 2188)\t1\n",
      "  (17595, 5030)\t1\n",
      "  (17595, 16061)\t1\n",
      "  (17595, 11517)\t1\n",
      "  (17595, 15632)\t1\n"
     ]
    }
   ],
   "source": [
    "def term_frequency_encoding(texts):\n",
    "    vectorizer = CountVectorizer()\n",
    "    embeddings = vectorizer.fit_transform(texts)\n",
    "    return embeddings\n",
    "embeddings_tf = term_frequency_encoding(texts)\n",
    "X_train_tf, X_test_tf, y_train_tf, y_test_tf = train_test_split(embeddings_tf, labels, test_size=0.2, random_state=42)\n",
    "print(embeddings_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3ccc5a1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Compressed Sparse Row sparse matrix of dtype 'float64'\n",
      "\twith 320602 stored elements and shape (17596, 20763)>\n",
      "  Coords\tValues\n",
      "  (0, 4634)\t0.33691958933300764\n",
      "  (0, 18506)\t0.32001164128817955\n",
      "  (0, 18453)\t0.15165197423800877\n",
      "  (0, 8227)\t0.25672936674983876\n",
      "  (0, 17690)\t0.47406059292584835\n",
      "  (0, 8173)\t0.4164903848802838\n",
      "  (0, 10461)\t0.37525962910152894\n",
      "  (0, 9215)\t0.13885066193037493\n",
      "  (0, 7736)\t0.36996279367905377\n",
      "  (1, 5579)\t0.2645688794841402\n",
      "  (1, 2972)\t0.26841797205609746\n",
      "  (1, 394)\t0.18577715954742052\n",
      "  (1, 20131)\t0.17923531261954773\n",
      "  (1, 9788)\t0.1259968016515918\n",
      "  (1, 17485)\t0.38989666328939804\n",
      "  (1, 7220)\t0.144594064993865\n",
      "  (1, 13004)\t0.18352720527959232\n",
      "  (1, 1096)\t0.25979668623580054\n",
      "  (1, 9800)\t0.23717831092225916\n",
      "  (1, 3977)\t0.4299948872975778\n",
      "  (1, 18653)\t0.0996453675495539\n",
      "  (1, 10719)\t0.16223888994565513\n",
      "  (1, 18404)\t0.09161042575119856\n",
      "  (1, 16541)\t0.4642690706501393\n",
      "  (2, 9788)\t0.41318131478103215\n",
      "  :\t:\n",
      "  (17594, 6498)\t0.11509783184101698\n",
      "  (17594, 123)\t0.13149178342671627\n",
      "  (17594, 53)\t0.1495229798298709\n",
      "  (17594, 6298)\t0.1160464422366907\n",
      "  (17594, 3914)\t0.1649683210198965\n",
      "  (17594, 15001)\t0.09794125123634168\n",
      "  (17594, 17530)\t0.1099555674278324\n",
      "  (17594, 16061)\t0.10021585829782433\n",
      "  (17594, 9902)\t0.11566119948784989\n",
      "  (17594, 1058)\t0.33028972945458035\n",
      "  (17594, 697)\t0.46020729908006214\n",
      "  (17594, 68)\t0.13906733593106763\n",
      "  (17594, 12285)\t0.14274259462141553\n",
      "  (17594, 16320)\t0.47491303494482706\n",
      "  (17594, 1074)\t0.16027285990999707\n",
      "  (17594, 15570)\t0.17125483752602344\n",
      "  (17594, 11487)\t0.16784841241434842\n",
      "  (17595, 17055)\t0.2151962698759533\n",
      "  (17595, 19474)\t0.2556041267640127\n",
      "  (17595, 5562)\t0.23971109481880692\n",
      "  (17595, 2188)\t0.3523417574675514\n",
      "  (17595, 5030)\t0.38260149254900994\n",
      "  (17595, 16061)\t0.3526345996734116\n",
      "  (17595, 11517)\t0.5397848851279822\n",
      "  (17595, 15632)\t0.38032642240310144\n",
      "(17596, 20763)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def tfidf_embedding(texts):\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    embeddings = vectorizer.fit_transform(texts)\n",
    "    return embeddings\n",
    "\n",
    "embeddings_tfidf = tfidf_embedding(texts)\n",
    "X_train_tfidf, X_test_tfidf, y_train_tfidf, y_test_tfidf = train_test_split(embeddings_tfidf, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "print(embeddings_tfidf)\n",
    "print(embeddings_tfidf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "15102600",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from scipy.sparse import csr_matrix\n",
    "\n",
    "\n",
    "# def term_frequency_encoding(texts):\n",
    "#     vectorizer = CountVectorizer()\n",
    "#     embeddings = vectorizer.fit_transform(texts)\n",
    "#     return embeddings\n",
    "# embedded_tf = term_frequency_encoding(texts)\n",
    "# X_train_tf, X_test_tf, y_train_tf, y_test_tf = train_test_split(embedded_tf, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# embeddings_tf_df = pd.DataFrame(embedded_tf.toarray())  \n",
    "\n",
    "# embeddings_tf_df['label'] = labels \n",
    "\n",
    "# # # Save DataFrame to CSV\n",
    "# # embeddings_tf_df.to_csv('embedded_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
