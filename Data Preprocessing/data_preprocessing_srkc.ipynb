{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "801840fc",
   "metadata": {},
   "source": [
    "# # Data Preprocessing\n",
    "The first step in our hate speech detection model involves collecting and preprocessing the data. This step is crucial as the quality and cleanliness of the data significantly affect the model's performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414a478a",
   "metadata": {},
   "source": [
    "We use the provided dataset (HateSpeechDetection.csv), which contains text data labeled as hate speech (1) or not hate speech (0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "057979bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Damn I thought they had strict gun laws in Ger...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I dont care about what it stands for or anythi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>It's not a group it's an idea lol</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>So it's not just America!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The dog is a spectacular dancer considering he...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>If ppl dont wear masks you complain... If ppl ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>We should send them All back  to africa</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Checking to see if it's whataboutism from the ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>As a european, I approve this.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Idk which of these groups to join, they're all...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Sometimes the messenger is just as important a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>This is the future we all want.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Wow the monkey calls someone else a monkey lol</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>They are the gypsies of America.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>I know that guy!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Text  Label\n",
       "0   Damn I thought they had strict gun laws in Ger...      0\n",
       "1   I dont care about what it stands for or anythi...      0\n",
       "2                   It's not a group it's an idea lol      0\n",
       "3                           So it's not just America!      0\n",
       "4   The dog is a spectacular dancer considering he...      0\n",
       "5   If ppl dont wear masks you complain... If ppl ...      0\n",
       "6             We should send them All back  to africa      1\n",
       "7   Checking to see if it's whataboutism from the ...      0\n",
       "8                      As a european, I approve this.      0\n",
       "9   Idk which of these groups to join, they're all...      0\n",
       "10  Sometimes the messenger is just as important a...      0\n",
       "11                    This is the future we all want.      0\n",
       "12     Wow the monkey calls someone else a monkey lol      1\n",
       "13                   They are the gypsies of America.      1\n",
       "14                                   I know that guy!      0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv(\"HateSpeechDetection.csv\")\n",
    "data.head(15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "20cacaaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17586</th>\n",
       "      <td>africans should be in a zoo with the other ani...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17587</th>\n",
       "      <td>I wouldn't want my daughter to marry a Chink</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17588</th>\n",
       "      <td>not anymore. they are like the shitty utube no...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17589</th>\n",
       "      <td>Yet still, better for a 750cc to seek a win (o...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17590</th>\n",
       "      <td>people this is new thread due to the impending...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17591</th>\n",
       "      <td>I find rats nicer and cleaner than most Chinese</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17592</th>\n",
       "      <td>Check out this niggar, they hit things like wi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17593</th>\n",
       "      <td>this country has become an absolute shambles, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17594</th>\n",
       "      <td>Me aged 16 = anti-Semitism is bad Me aged 18 =...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17595</th>\n",
       "      <td>so messed up saying blacks don't deserve rights</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Text  Label\n",
       "17586  africans should be in a zoo with the other ani...      1\n",
       "17587       I wouldn't want my daughter to marry a Chink      1\n",
       "17588  not anymore. they are like the shitty utube no...      1\n",
       "17589  Yet still, better for a 750cc to seek a win (o...      0\n",
       "17590  people this is new thread due to the impending...      0\n",
       "17591    I find rats nicer and cleaner than most Chinese      1\n",
       "17592  Check out this niggar, they hit things like wi...      1\n",
       "17593  this country has become an absolute shambles, ...      0\n",
       "17594  Me aged 16 = anti-Semitism is bad Me aged 18 =...      1\n",
       "17595    so messed up saying blacks don't deserve rights      0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2639c66b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17596 entries, 0 to 17595\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Text    17596 non-null  object\n",
      " 1   Label   17596 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 275.1+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be2a486",
   "metadata": {},
   "source": [
    "After observing the dataset, we can infer that we need to clean and transform the raw text data into a format suitable for our  model. This involves several sub-steps:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "920d490f",
   "metadata": {},
   "source": [
    "Removing Extra Spaces: Normalize the spacing in the text to remove any extra spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c59a9dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_extra_spaces(text):\n",
    "    return re.sub(r'\\s+', ' ', text) #the re.sub function replaces one or more whitespace characters (\\s+) with a single space.\n",
    "data['Text'] = data['Text'].apply(remove_extra_spaces)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16839dd9",
   "metadata": {},
   "source": [
    "Remove usernames: Same as for the URL, a username in a text won’t give any valuable information because it won’t be recognized as a word carrying meaning. We will then remove it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0cc30431",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_username(text):\n",
    "    return re.sub(r\"@\\S+\", \"\",text) \n",
    "#We used pattern “@\\S+” -> it suggests string group which starts with ‘@’ and followed by non-whitespace character(\\S), ‘+’ means repeatition of preceding character one or more times\n",
    "\n",
    "data['Text'] = data['Text'].apply(remove_username)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4523437a",
   "metadata": {},
   "source": [
    "Remove Hashtags: Hashtags are hard to apprehend, but usually contain useful information about the context of a text and its content. The problem with hashtags is that the words are all after the other, without a space. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3757241b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17591</th>\n",
       "      <td>I find rats nicer and cleaner than most Chinese</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17592</th>\n",
       "      <td>Check out this niggar, they hit things like wi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17593</th>\n",
       "      <td>this country has become an absolute shambles, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17594</th>\n",
       "      <td>Me aged 16 = anti-Semitism is bad Me aged 18 =...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17595</th>\n",
       "      <td>so messed up saying blacks don't deserve rights</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Text  Label\n",
       "17591    I find rats nicer and cleaner than most Chinese      1\n",
       "17592  Check out this niggar, they hit things like wi...      1\n",
       "17593  this country has become an absolute shambles, ...      0\n",
       "17594  Me aged 16 = anti-Semitism is bad Me aged 18 =...      1\n",
       "17595    so messed up saying blacks don't deserve rights      0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_hashtags(text):\n",
    "    return re.sub(r'#', '', text)\n",
    "# replacing the character(\"#\") with \"\" but not removing the term.\n",
    "\n",
    "data['Text'] = data['Text'].apply(remove_hashtags)\n",
    "data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a72fe8dc",
   "metadata": {},
   "source": [
    "Handling Contractions\n",
    "\n",
    "Handling contractions in text is an important step in text preprocessing, especially for tasks like hate speech detection where understanding the full meaning of the words is crucial. Contractions are shortened forms of words or combinations of words created by omitting certain letters and sounds (e.g., \"don't\" for \"do not\", \"I'm\" for \"I am\"). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "57dee0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import contractions\n",
    "data['Text']=data['Text'].apply(lambda x:contractions.fix(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcdec827",
   "metadata": {},
   "source": [
    "Lowercasing: Convert all text to lowercase to ensure uniformity, as the model should treat \"Hate\" and \"hate\" as the same word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "81013400",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_lower(text):\n",
    "    return text.lower()\n",
    "data['Text'] = data['Text'].apply(text_lower)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d445a83",
   "metadata": {},
   "source": [
    "Removing Punctuation: Strip out punctuation to focus on the words themselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0e4287b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17591</th>\n",
       "      <td>i find rats nicer and cleaner than most chinese</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17592</th>\n",
       "      <td>check out this niggar they hit things like wil...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17593</th>\n",
       "      <td>this country has become an absolute shambles t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17594</th>\n",
       "      <td>me aged 16  antisemitism is bad me aged 18  an...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17595</th>\n",
       "      <td>so messed up saying blacks do not deserve rights</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Text  Label\n",
       "17591    i find rats nicer and cleaner than most chinese      1\n",
       "17592  check out this niggar they hit things like wil...      1\n",
       "17593  this country has become an absolute shambles t...      0\n",
       "17594  me aged 16  antisemitism is bad me aged 18  an...      1\n",
       "17595   so messed up saying blacks do not deserve rights      0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_punctuation(text):\n",
    "    return re.sub(r'[^\\w\\s]', '', text)\n",
    "    #\\w: Represents any alphanumeric character (equivalent to [a-zA-Z0-9_]).\n",
    "    #\\s: Denotes any whitespace character, such as space, tab, or newline.\n",
    "    # so it defines the other than a alphanumeric character followed by a single space, ('^' for negation) remove other characters\n",
    "\n",
    "data['Text'] = data['Text'].apply(remove_punctuation)\n",
    "data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef16c84",
   "metadata": {},
   "source": [
    "Remove URLs: URLs do not give any information when we try to analyze text from words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "049c78a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_url(text):\n",
    "    return re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
    "# it identifies the words starting with http or https or www and ending with a non-white space Character(\\S) then remove it\n",
    "\n",
    "data['Text'] = data['Text'].apply(remove_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3bf0e6",
   "metadata": {},
   "source": [
    "Removing Short words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "926a9f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Text'] = data['Text'].apply(lambda x: ' '.join([word for word in x.split() if len(word) >= 3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a805b418",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>damn thought they had strict gun laws germany</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>not care about what stands for anything its co...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>not group idea lol</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>not just america</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the dog spectacular dancer considering has two...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17591</th>\n",
       "      <td>find rats nicer and cleaner than most chinese</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17592</th>\n",
       "      <td>check out this niggar they hit things like wil...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17593</th>\n",
       "      <td>this country has become absolute shambles the ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17594</th>\n",
       "      <td>aged antisemitism bad aged antisemitism does n...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17595</th>\n",
       "      <td>messed saying blacks not deserve rights</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17596 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Text  Label\n",
       "0          damn thought they had strict gun laws germany      0\n",
       "1      not care about what stands for anything its co...      0\n",
       "2                                     not group idea lol      0\n",
       "3                                       not just america      0\n",
       "4      the dog spectacular dancer considering has two...      0\n",
       "...                                                  ...    ...\n",
       "17591      find rats nicer and cleaner than most chinese      1\n",
       "17592  check out this niggar they hit things like wil...      1\n",
       "17593  this country has become absolute shambles the ...      0\n",
       "17594  aged antisemitism bad aged antisemitism does n...      1\n",
       "17595            messed saying blacks not deserve rights      0\n",
       "\n",
       "[17596 rows x 2 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b27424c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\balui\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\balui\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\balui\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "# Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "083248fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatizers(text):\n",
    "    text = nltk.word_tokenize(text)\n",
    "    word=[]\n",
    "    for i in text:\n",
    "        if i not in stopwords.words('english'):\n",
    "            word.append(lemmatizer.lemmatize(i))\n",
    "        else:\n",
    "            word.append(i)\n",
    "    return ' '.join(word)\n",
    "data['Text'] = data['Text'].apply(lemmatizers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1bcf2d18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>damn thought they had strict gun law germany</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>not care about what stand for anything its con...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>not group idea lol</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>not just america</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the dog spectacular dancer considering has two...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17591</th>\n",
       "      <td>find rat nicer and cleaner than most chinese</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17592</th>\n",
       "      <td>check out this niggar they hit thing like wild...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17593</th>\n",
       "      <td>this country has become absolute shamble the a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17594</th>\n",
       "      <td>aged antisemitism bad aged antisemitism does n...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17595</th>\n",
       "      <td>messed saying black not deserve right</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17596 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Text  Label\n",
       "0           damn thought they had strict gun law germany      0\n",
       "1      not care about what stand for anything its con...      0\n",
       "2                                     not group idea lol      0\n",
       "3                                       not just america      0\n",
       "4      the dog spectacular dancer considering has two...      0\n",
       "...                                                  ...    ...\n",
       "17591       find rat nicer and cleaner than most chinese      1\n",
       "17592  check out this niggar they hit thing like wild...      1\n",
       "17593  this country has become absolute shamble the a...      0\n",
       "17594  aged antisemitism bad aged antisemitism does n...      1\n",
       "17595              messed saying black not deserve right      0\n",
       "\n",
       "[17596 rows x 2 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c376d43e",
   "metadata": {},
   "source": [
    "Text Vectorization:\n",
    "Vectorization is the process of converting text into numerical representations. The TextVectorization layer is designed to standardize the text data, tokenize it, and convert it into integer sequences that can be used as input for deep learning model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7e341546",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0             damn thought they had strict gun law germany\n",
       "1        not care about what stand for anything its con...\n",
       "2                                       not group idea lol\n",
       "3                                         not just america\n",
       "4        the dog spectacular dancer considering has two...\n",
       "                               ...                        \n",
       "17591         find rat nicer and cleaner than most chinese\n",
       "17592    check out this niggar they hit thing like wild...\n",
       "17593    this country has become absolute shamble the a...\n",
       "17594    aged antisemitism bad aged antisemitism does n...\n",
       "17595                messed saying black not deserve right\n",
       "Name: Text, Length: 17596, dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data['Text']\n",
    "y = data[data.columns[1]].values\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ad109ffc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b194f07",
   "metadata": {},
   "source": [
    "Vocabulary Size (max_tokens=10000):\n",
    "\n",
    "By setting max_tokens to 10,000, we limit the vocabulary to the 10,000 most frequent words in the dataset. This helps in reducing the computational complexity and memory usage while retaining the most important words for the task.\n",
    "\n",
    "Sequence Length (output_sequence_length=350):\n",
    "\n",
    "The output_sequence_length parameter ensures that all text sequences are of equal length 35.0 tokens in this case). Shorter sequences will be padded (usually with zeros), and longer sequences will be truncated. This uniformity is necessary for efficient batch processing and model training.\n",
    "\n",
    "Integer Token Indices (output_mode='int'):\n",
    "\n",
    "The output_mode='int' setting indicates that the output will be integer indices of tokens. This is a common approach in NLP tasks, where each unique token in the vocabulary is assigned a unique integer index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6d8f4238",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(17596, 300), dtype=int64, numpy=\n",
       "array([[ 414,  251,    8, ...,    0,    0,    0],\n",
       "       [   5,  157,   28, ...,    0,    0,    0],\n",
       "       [   5,  172,  249, ...,    0,    0,    0],\n",
       "       ...,\n",
       "       [  11,   51,   57, ...,    0,    0,    0],\n",
       "       [2125, 1532,  144, ...,    0,    0,    0],\n",
       "       [2424,  168,   24, ...,    0,    0,    0]], dtype=int64)>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.layers import TextVectorization\n",
    "vectorizer = TextVectorization(max_tokens=10000,\n",
    "                               output_sequence_length=300,\n",
    "                               output_mode='int')\n",
    "vectorizer.adapt(X.values)\n",
    "vectorized_text = vectorizer(X.values)\n",
    "vectorized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c716e6a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " '[UNK]',\n",
       " 'the',\n",
       " 'and',\n",
       " 'are',\n",
       " 'not',\n",
       " 'you',\n",
       " 'that',\n",
       " 'they',\n",
       " 'for',\n",
       " 'have',\n",
       " 'this',\n",
       " 'people',\n",
       " 'with',\n",
       " 'all',\n",
       " 'but',\n",
       " 'like',\n",
       " 'can',\n",
       " 'woman',\n",
       " 'just',\n",
       " 'their',\n",
       " 'them',\n",
       " 'was',\n",
       " 'will',\n",
       " 'black',\n",
       " 'what',\n",
       " 'would',\n",
       " 'who',\n",
       " 'about',\n",
       " 'there',\n",
       " 'from',\n",
       " 'your',\n",
       " 'get',\n",
       " 'because',\n",
       " 'fucking',\n",
       " 'should',\n",
       " 'when',\n",
       " 'one',\n",
       " 'she',\n",
       " 'think',\n",
       " 'more',\n",
       " 'want',\n",
       " 'how',\n",
       " 'out',\n",
       " 'white',\n",
       " 'why',\n",
       " 'being',\n",
       " 'know',\n",
       " 'our',\n",
       " 'these',\n",
       " 'muslim',\n",
       " 'country',\n",
       " 'some',\n",
       " 'men',\n",
       " 'even',\n",
       " 'make',\n",
       " 'her',\n",
       " 'has',\n",
       " 'fuck',\n",
       " 'only',\n",
       " 'hate',\n",
       " 'say',\n",
       " 'than',\n",
       " 'were',\n",
       " 'need',\n",
       " 'really',\n",
       " 'time',\n",
       " 'now',\n",
       " 'gay',\n",
       " 'here',\n",
       " 'see',\n",
       " 'any',\n",
       " 'most',\n",
       " 'good',\n",
       " 'those',\n",
       " 'shit',\n",
       " 'other',\n",
       " 'then',\n",
       " 'never',\n",
       " 'thing',\n",
       " 'does',\n",
       " 'right',\n",
       " 'look',\n",
       " 'way',\n",
       " 'many',\n",
       " 'did',\n",
       " 'been',\n",
       " 'jew',\n",
       " 'man',\n",
       " 'life',\n",
       " 'going',\n",
       " 'had',\n",
       " 'much',\n",
       " 'world',\n",
       " 'too',\n",
       " 'its',\n",
       " 'his',\n",
       " 'could',\n",
       " 'love',\n",
       " 'into',\n",
       " 'year',\n",
       " 'off',\n",
       " 'which',\n",
       " 'take',\n",
       " 'over',\n",
       " 'back',\n",
       " 'always',\n",
       " 'day',\n",
       " 'also',\n",
       " 'him',\n",
       " 'got',\n",
       " 'refugee',\n",
       " 'let',\n",
       " 'guy',\n",
       " 'very',\n",
       " 'come',\n",
       " 'such',\n",
       " 'well',\n",
       " 'actually',\n",
       " 'still',\n",
       " 'child',\n",
       " 'asian',\n",
       " 'immigrant',\n",
       " 'work',\n",
       " 'lot',\n",
       " 'race',\n",
       " 'kid',\n",
       " 'every',\n",
       " 'same',\n",
       " 'feel',\n",
       " 'better',\n",
       " 'believe',\n",
       " 'something',\n",
       " 'trans',\n",
       " 'where',\n",
       " 'girl',\n",
       " 'own',\n",
       " 'down',\n",
       " 'society',\n",
       " 'nothing',\n",
       " 'friend',\n",
       " 'mean',\n",
       " 'stop',\n",
       " 'person',\n",
       " 'bad',\n",
       " 'racist',\n",
       " 'someone',\n",
       " 'said',\n",
       " 'live',\n",
       " 'problem',\n",
       " 'anyone',\n",
       " 'tell',\n",
       " 'after',\n",
       " 'everyone',\n",
       " 'place',\n",
       " 'against',\n",
       " 'keep',\n",
       " 'care',\n",
       " 'real',\n",
       " 'bitch',\n",
       " 'anything',\n",
       " 'around',\n",
       " 'call',\n",
       " 'ever',\n",
       " 'wrong',\n",
       " 'new',\n",
       " 'first',\n",
       " 'give',\n",
       " 'saying',\n",
       " 'money',\n",
       " 'use',\n",
       " 'word',\n",
       " 'group',\n",
       " 'before',\n",
       " 'reason',\n",
       " 'nigger',\n",
       " 'family',\n",
       " 'getting',\n",
       " 'human',\n",
       " 'american',\n",
       " 'must',\n",
       " 'show',\n",
       " 'themselves',\n",
       " 'doing',\n",
       " 'school',\n",
       " 'great',\n",
       " 'enough',\n",
       " 'sure',\n",
       " 'end',\n",
       " 'indian',\n",
       " 'fact',\n",
       " 'long',\n",
       " 'job',\n",
       " 'find',\n",
       " 'having',\n",
       " 'though',\n",
       " 'while',\n",
       " 'help',\n",
       " 'everything',\n",
       " 'matter',\n",
       " 'best',\n",
       " 'kind',\n",
       " 'disgusting',\n",
       " 'made',\n",
       " 'used',\n",
       " 'trump',\n",
       " 'stupid',\n",
       " 'called',\n",
       " 'sex',\n",
       " 'try',\n",
       " 'kill',\n",
       " 'chinese',\n",
       " 'lol',\n",
       " 'again',\n",
       " 'next',\n",
       " 'home',\n",
       " 'point',\n",
       " 'government',\n",
       " 'big',\n",
       " 'another',\n",
       " 'god',\n",
       " 'old',\n",
       " 'issue',\n",
       " 'culture',\n",
       " 'jewish',\n",
       " 'put',\n",
       " 'trying',\n",
       " 'start',\n",
       " 'different',\n",
       " 'without',\n",
       " 'true',\n",
       " 'state',\n",
       " 'little',\n",
       " 'full',\n",
       " 'face',\n",
       " 'understand',\n",
       " 'le',\n",
       " 'die',\n",
       " 'away',\n",
       " 'literally',\n",
       " 'hope',\n",
       " 'few',\n",
       " 'allowed',\n",
       " 'last',\n",
       " 'told',\n",
       " 'medium',\n",
       " 'today',\n",
       " 'faggot',\n",
       " 'talk',\n",
       " 'idea',\n",
       " 'else',\n",
       " 'thought',\n",
       " 'yes',\n",
       " 'living',\n",
       " 'house',\n",
       " 'female',\n",
       " 'as',\n",
       " 'until',\n",
       " 'seen',\n",
       " 'least',\n",
       " 'population',\n",
       " 'liberal',\n",
       " 'two',\n",
       " 'hard',\n",
       " 'gender',\n",
       " 'free',\n",
       " 'dirty',\n",
       " 'change',\n",
       " 'part',\n",
       " 'others',\n",
       " 'hell',\n",
       " 'stay',\n",
       " 'lesbian',\n",
       " 'ugly',\n",
       " 'through',\n",
       " 'please',\n",
       " 'pretty',\n",
       " 'nice',\n",
       " 'deserve',\n",
       " 'worse',\n",
       " 'support',\n",
       " 'since',\n",
       " 'sick',\n",
       " 'war',\n",
       " 'saw',\n",
       " 'law',\n",
       " 'boy',\n",
       " 'might',\n",
       " 'yet',\n",
       " 'community',\n",
       " 'animal',\n",
       " 'wish',\n",
       " 'opinion',\n",
       " 'done',\n",
       " 'british',\n",
       " 'yourself',\n",
       " 'yeah',\n",
       " 'post',\n",
       " 'however',\n",
       " 'between',\n",
       " 'poor',\n",
       " 'high',\n",
       " 'making',\n",
       " 'leave',\n",
       " 'crime',\n",
       " 'african',\n",
       " 'working',\n",
       " 'may',\n",
       " 'video',\n",
       " 'parent',\n",
       " 'arab',\n",
       " 'course',\n",
       " 'baby',\n",
       " 'once',\n",
       " 'left',\n",
       " 'imagine',\n",
       " 'america',\n",
       " 'worst',\n",
       " 'looking',\n",
       " 'cunt',\n",
       " 'probably',\n",
       " 'mind',\n",
       " 'street',\n",
       " 'scum',\n",
       " 'normal',\n",
       " 'idiot',\n",
       " 'whole',\n",
       " 'talking',\n",
       " 'europe',\n",
       " 'dog',\n",
       " 'death',\n",
       " 'city',\n",
       " 'useless',\n",
       " 'suck',\n",
       " 'remember',\n",
       " 'already',\n",
       " 'maybe',\n",
       " 'far',\n",
       " 'control',\n",
       " 'terrorist',\n",
       " 'pay',\n",
       " 'seems',\n",
       " 'both',\n",
       " 'absolutely',\n",
       " 'police',\n",
       " 'name',\n",
       " 'act',\n",
       " 'honest',\n",
       " 'european',\n",
       " 'power',\n",
       " 'each',\n",
       " 'wear',\n",
       " 'term',\n",
       " 'stand',\n",
       " 'using',\n",
       " 'read',\n",
       " 'history',\n",
       " 'food',\n",
       " 'coming',\n",
       " 'become',\n",
       " 'able',\n",
       " 'male',\n",
       " 'hey',\n",
       " 'happy',\n",
       " 'lie',\n",
       " 'instead',\n",
       " 'either',\n",
       " 'class',\n",
       " 'bullshit',\n",
       " 'wonder',\n",
       " 'religion',\n",
       " 'nazi',\n",
       " 'islam',\n",
       " 'came',\n",
       " 'single',\n",
       " 'taking',\n",
       " 'covid',\n",
       " 'calling',\n",
       " 'born',\n",
       " 'area',\n",
       " 'went',\n",
       " 'watch',\n",
       " 'found',\n",
       " 'etc',\n",
       " 'turn',\n",
       " 'monkey',\n",
       " 'mixed',\n",
       " 'million',\n",
       " 'head',\n",
       " 'fucked',\n",
       " 'whatever',\n",
       " 'truth',\n",
       " 'racism',\n",
       " 'question',\n",
       " 'honestly',\n",
       " 'completely',\n",
       " 'body',\n",
       " 'africa',\n",
       " 'young',\n",
       " 'under',\n",
       " 'rather',\n",
       " 'politician',\n",
       " 'fight',\n",
       " 'dumb',\n",
       " 'agree',\n",
       " 'trash',\n",
       " 'sorry',\n",
       " 'exist',\n",
       " 'case',\n",
       " 'run',\n",
       " 'rest',\n",
       " 'number',\n",
       " 'nation',\n",
       " 'eat',\n",
       " 'damn',\n",
       " 'week',\n",
       " 'simply',\n",
       " 'rape',\n",
       " 'foreigner',\n",
       " 'dude',\n",
       " 'disabled',\n",
       " 'thanks',\n",
       " 'quite',\n",
       " 'myself',\n",
       " 'mental',\n",
       " 'definitely',\n",
       " 'english',\n",
       " 'wife',\n",
       " 'especially',\n",
       " 'criminal',\n",
       " 'christian',\n",
       " 'car',\n",
       " 'attention',\n",
       " 'almost',\n",
       " 'whore',\n",
       " 'often',\n",
       " 'likely',\n",
       " 'hand',\n",
       " 'guess',\n",
       " 'comment',\n",
       " 'shitty',\n",
       " 'nigga',\n",
       " 'story',\n",
       " 'seem',\n",
       " 'sad',\n",
       " 'retard',\n",
       " 'seriously',\n",
       " 'dick',\n",
       " 'rule',\n",
       " 'proud',\n",
       " 'learn',\n",
       " 'hear',\n",
       " 'donât',\n",
       " 'stuff',\n",
       " 'speak',\n",
       " 'respect',\n",
       " 'move',\n",
       " 'gypsy',\n",
       " 'difference',\n",
       " 'view',\n",
       " 'social',\n",
       " 'sense',\n",
       " 'relationship',\n",
       " 'news',\n",
       " 'immigration',\n",
       " 'side',\n",
       " 'seeing',\n",
       " 'political',\n",
       " 'open',\n",
       " 'given',\n",
       " 'dead',\n",
       " 'bit',\n",
       " 'happen',\n",
       " 'claim',\n",
       " 'blame',\n",
       " 'ask',\n",
       " 'wanted',\n",
       " 'type',\n",
       " 'started',\n",
       " 'sexual',\n",
       " 'night',\n",
       " 'attack',\n",
       " 'smart',\n",
       " 'public',\n",
       " 'piece',\n",
       " 'killed',\n",
       " 'evil',\n",
       " 'vote',\n",
       " 'value',\n",
       " 'level',\n",
       " 'heard',\n",
       " 'during',\n",
       " 'thinking',\n",
       " 'slave',\n",
       " 'play',\n",
       " 'choice',\n",
       " 'china',\n",
       " 'son',\n",
       " 'rat',\n",
       " 'party',\n",
       " 'order',\n",
       " 'experience',\n",
       " 'ago',\n",
       " 'violent',\n",
       " 'thread',\n",
       " 'straight',\n",
       " 'obama',\n",
       " 'due',\n",
       " 'beautiful',\n",
       " 'shut',\n",
       " 'self',\n",
       " 'middle',\n",
       " 'land',\n",
       " 'exactly',\n",
       " 'age',\n",
       " 'wait',\n",
       " 'totally',\n",
       " 'sound',\n",
       " 'lazy',\n",
       " 'game',\n",
       " 'future',\n",
       " 'funny',\n",
       " 'couple',\n",
       " 'brain',\n",
       " 'weird',\n",
       " 'skin',\n",
       " 'ireland',\n",
       " 'common',\n",
       " 'together',\n",
       " 'nature',\n",
       " 'destroy',\n",
       " 'belong',\n",
       " 'based',\n",
       " 'worth',\n",
       " 'violence',\n",
       " 'towards',\n",
       " 'shot',\n",
       " 'month',\n",
       " 'homosexual',\n",
       " 'example',\n",
       " 'welcome',\n",
       " 'rich',\n",
       " 'mask',\n",
       " 'horrible',\n",
       " 'everywhere',\n",
       " 'benefit',\n",
       " 'system',\n",
       " 'specie',\n",
       " 'language',\n",
       " 'feeling',\n",
       " 'dress',\n",
       " 'absolute',\n",
       " 'past',\n",
       " 'marriage',\n",
       " 'deal',\n",
       " 'citizen',\n",
       " 'buy',\n",
       " 'murder',\n",
       " 'met',\n",
       " 'massive',\n",
       " 'crazy',\n",
       " 'clearly',\n",
       " 'awful',\n",
       " 'anyway',\n",
       " 'virus',\n",
       " 'near',\n",
       " 'mexican',\n",
       " 'longer',\n",
       " 'bunch',\n",
       " 'brother',\n",
       " 'asylum',\n",
       " 'sort',\n",
       " 'picture',\n",
       " 'joke',\n",
       " 'gone',\n",
       " 'go',\n",
       " 'crap',\n",
       " 'accept',\n",
       " 'whether',\n",
       " 'okay',\n",
       " 'majority',\n",
       " 'eye',\n",
       " 'equal',\n",
       " 'earth',\n",
       " 'business',\n",
       " 'basically',\n",
       " 'usually',\n",
       " 'tranny',\n",
       " 'thank',\n",
       " 'sake',\n",
       " 'possible',\n",
       " 'nike',\n",
       " 'mother',\n",
       " 'modern',\n",
       " 'important',\n",
       " 'hot',\n",
       " 'haha',\n",
       " 'east',\n",
       " 'drug',\n",
       " 'daughter',\n",
       " 'dark',\n",
       " 'conservative',\n",
       " 'brown',\n",
       " 'britain',\n",
       " 'anymore',\n",
       " 'short',\n",
       " 'reality',\n",
       " 'illegal',\n",
       " 'bloody',\n",
       " 'alone',\n",
       " 'actual',\n",
       " 'sometimes',\n",
       " 'rate',\n",
       " 'mate',\n",
       " 'happens',\n",
       " 'fun',\n",
       " 'easy',\n",
       " 'abuse',\n",
       " '100',\n",
       " 'wearing',\n",
       " 'telling',\n",
       " 'reddit',\n",
       " 'racial',\n",
       " 'pussy',\n",
       " 'low',\n",
       " 'justin',\n",
       " 'individual',\n",
       " 'fag',\n",
       " 'entire',\n",
       " 'chink',\n",
       " 'break',\n",
       " 'action',\n",
       " 'wow',\n",
       " 'trust',\n",
       " 'tried',\n",
       " 'taken',\n",
       " 'non',\n",
       " 'half',\n",
       " 'hair',\n",
       " 'date',\n",
       " 'victim',\n",
       " 'situation',\n",
       " 'plan',\n",
       " 'neighbour',\n",
       " 'bring',\n",
       " 'tax',\n",
       " 'rid',\n",
       " 'obviously',\n",
       " 'marry',\n",
       " 'local',\n",
       " 'knew',\n",
       " 'husband',\n",
       " 'forget',\n",
       " 'fake',\n",
       " 'dangerous',\n",
       " 'cry',\n",
       " 'brexit',\n",
       " 'amount',\n",
       " 'win',\n",
       " 'save',\n",
       " 'rapist',\n",
       " 'priest',\n",
       " 'minority',\n",
       " 'indigenous',\n",
       " 'follow',\n",
       " 'finally',\n",
       " 'fault',\n",
       " 'fair',\n",
       " 'cool',\n",
       " 'clear',\n",
       " 'answer',\n",
       " 'western',\n",
       " 'west',\n",
       " 'top',\n",
       " 'took',\n",
       " 'sister',\n",
       " 'married',\n",
       " 'killing',\n",
       " 'ignorant',\n",
       " 'fine',\n",
       " 'fear',\n",
       " 'extremely',\n",
       " 'expect',\n",
       " 'book',\n",
       " 'banned',\n",
       " 'angry',\n",
       " 'within',\n",
       " 'truly',\n",
       " 'town',\n",
       " 'threat',\n",
       " 'president',\n",
       " 'pakistani',\n",
       " 'listen',\n",
       " 'general',\n",
       " 'fat',\n",
       " 'belief',\n",
       " 'apparently',\n",
       " 'amazing',\n",
       " 'treated',\n",
       " 'transgender',\n",
       " 'pig',\n",
       " 'otherwise',\n",
       " 'native',\n",
       " 'mostly',\n",
       " 'known',\n",
       " 'glad',\n",
       " 'certain',\n",
       " 'camel',\n",
       " 'behind',\n",
       " 'among',\n",
       " 'twat',\n",
       " 'tory',\n",
       " 'terrible',\n",
       " 'small',\n",
       " 'share',\n",
       " 'shame',\n",
       " 'quality',\n",
       " 'pain',\n",
       " 'line',\n",
       " 'large',\n",
       " 'kike',\n",
       " 'health',\n",
       " 'happened',\n",
       " 'fit',\n",
       " 'behavior',\n",
       " 'beat',\n",
       " 'watching',\n",
       " 'soon',\n",
       " 'safe',\n",
       " 'ruin',\n",
       " 'moment',\n",
       " 'join',\n",
       " 'hurt',\n",
       " 'huge',\n",
       " 'germany',\n",
       " 'german',\n",
       " 'enjoy',\n",
       " 'despite',\n",
       " 'consider',\n",
       " 'cat',\n",
       " 'wtf',\n",
       " 'surprised',\n",
       " 'rubbish',\n",
       " 'loser',\n",
       " 'hour',\n",
       " 'doctor',\n",
       " 'argument',\n",
       " 'allow',\n",
       " 'nobody',\n",
       " 'itâs',\n",
       " 'hit',\n",
       " 'ethnic',\n",
       " 'cop',\n",
       " 'colour',\n",
       " 'close',\n",
       " 'border',\n",
       " 'associated',\n",
       " 'unless',\n",
       " 'playing',\n",
       " 'mass',\n",
       " 'mad',\n",
       " 'lgbt',\n",
       " 'including',\n",
       " 'homo',\n",
       " 'himself',\n",
       " 'filthy',\n",
       " 'drink',\n",
       " 'dad',\n",
       " 'cut',\n",
       " 'check',\n",
       " 'century',\n",
       " 'burn',\n",
       " 'ball',\n",
       " 'three',\n",
       " 'strong',\n",
       " 'speech',\n",
       " 'set',\n",
       " 'service',\n",
       " 'serious',\n",
       " 'phone',\n",
       " 'natural',\n",
       " 'lack',\n",
       " 'inferior',\n",
       " 'identity',\n",
       " 'gross',\n",
       " 'form',\n",
       " 'force',\n",
       " 'father',\n",
       " 'economy',\n",
       " 'corona',\n",
       " 'complete',\n",
       " 'charge',\n",
       " 'blood',\n",
       " 'average',\n",
       " 'tend',\n",
       " 'team',\n",
       " 'smell',\n",
       " 'similar',\n",
       " 'period',\n",
       " 'online',\n",
       " 'mum',\n",
       " 'lose',\n",
       " 'india',\n",
       " 'except',\n",
       " 'created',\n",
       " 'sport',\n",
       " 'slavery',\n",
       " 'second',\n",
       " 'policy',\n",
       " 'photo',\n",
       " 'pas',\n",
       " 'london',\n",
       " 'israel',\n",
       " 'hitler',\n",
       " 'decent',\n",
       " 'clean',\n",
       " 'canada',\n",
       " 'blm',\n",
       " 'asshole',\n",
       " 'along',\n",
       " 'afraid',\n",
       " 'across',\n",
       " 'turned',\n",
       " 'study',\n",
       " 'slut',\n",
       " 'sleep',\n",
       " 'shop',\n",
       " 'result',\n",
       " 'negro',\n",
       " 'music',\n",
       " 'morning',\n",
       " 'meet',\n",
       " 'folk',\n",
       " 'explain',\n",
       " 'dating',\n",
       " 'ape',\n",
       " 'treat',\n",
       " 'slur',\n",
       " 'red',\n",
       " 'realise',\n",
       " 'positive',\n",
       " 'planet',\n",
       " 'personal',\n",
       " 'lost',\n",
       " 'lady',\n",
       " 'giving',\n",
       " 'girlfriend',\n",
       " 'died',\n",
       " 'account',\n",
       " 'usa',\n",
       " 'therefore',\n",
       " 'super',\n",
       " 'step',\n",
       " 'movie',\n",
       " 'light',\n",
       " 'legal',\n",
       " 'jesus',\n",
       " 'freedom',\n",
       " 'diversity',\n",
       " 'create',\n",
       " 'considered',\n",
       " 'computer',\n",
       " 'cockroach',\n",
       " 'biggest',\n",
       " 'behaviour',\n",
       " 'united',\n",
       " 'unfortunately',\n",
       " 'tired',\n",
       " 'terrorism',\n",
       " 'seeker',\n",
       " 'perfect',\n",
       " 'partner',\n",
       " 'outside',\n",
       " 'lying',\n",
       " 'inside',\n",
       " 'grow',\n",
       " 'generation',\n",
       " 'forced',\n",
       " 'asked',\n",
       " 'waste',\n",
       " 'walk',\n",
       " 'thousand',\n",
       " 'send',\n",
       " 'national',\n",
       " 'innocent',\n",
       " 'false',\n",
       " 'current',\n",
       " 'continue',\n",
       " 'civilization',\n",
       " 'bisexual',\n",
       " 'worked',\n",
       " 'teacher',\n",
       " 'teach',\n",
       " 'supremacist',\n",
       " 'steal',\n",
       " 'south',\n",
       " 'somehow',\n",
       " 'scared',\n",
       " 'role',\n",
       " 'pregnant',\n",
       " 'obvious',\n",
       " 'nasty',\n",
       " 'moral',\n",
       " 'looked',\n",
       " 'lmao',\n",
       " 'letting',\n",
       " 'lead',\n",
       " 'ill',\n",
       " 'france',\n",
       " 'fall',\n",
       " 'donald',\n",
       " 'coronavirus',\n",
       " 'wild',\n",
       " 'welfare',\n",
       " 'upon',\n",
       " 'twitter',\n",
       " 'traveller',\n",
       " 'total',\n",
       " 'throw',\n",
       " 'queer',\n",
       " 'pure',\n",
       " 'position',\n",
       " 'peace',\n",
       " 'opposite',\n",
       " 'office',\n",
       " 'nonsense',\n",
       " 'moron',\n",
       " 'mistake',\n",
       " 'migrant',\n",
       " 'load',\n",
       " 'japanese',\n",
       " 'iâm',\n",
       " 'islamic',\n",
       " 'illness',\n",
       " 'foreign',\n",
       " 'difficult',\n",
       " 'degenerate',\n",
       " 'breed',\n",
       " 'boris',\n",
       " 'bieber',\n",
       " 'annoying',\n",
       " 'water',\n",
       " 'special',\n",
       " 'russian',\n",
       " 'pandemic',\n",
       " 'freak',\n",
       " 'fighting',\n",
       " 'fan',\n",
       " 'early',\n",
       " 'door',\n",
       " 'disagree',\n",
       " 'decision',\n",
       " 'compared',\n",
       " 'clothes',\n",
       " 'choose',\n",
       " 'character',\n",
       " 'chance',\n",
       " 'cancer',\n",
       " 'became',\n",
       " 'according',\n",
       " 'willing',\n",
       " 'trouble',\n",
       " 'shoot',\n",
       " 'ruined',\n",
       " 'ready',\n",
       " 'raise',\n",
       " 'prison',\n",
       " 'politics',\n",
       " 'meant',\n",
       " 'internet',\n",
       " 'holocaust',\n",
       " 'herself',\n",
       " 'fucker',\n",
       " 'french',\n",
       " 'easily',\n",
       " 'correct',\n",
       " 'company',\n",
       " 'bastard',\n",
       " 'article',\n",
       " 'university',\n",
       " 'treatment',\n",
       " 'traitor',\n",
       " 'stick',\n",
       " 'simple',\n",
       " 'showing',\n",
       " 'seek',\n",
       " 'rude',\n",
       " 'road',\n",
       " 'putting',\n",
       " 'prefer',\n",
       " 'interesting',\n",
       " 'intelligence',\n",
       " 'hating',\n",
       " 'ground',\n",
       " 'genocide',\n",
       " 'forever',\n",
       " 'following',\n",
       " 'creature',\n",
       " 'bro',\n",
       " 'bed',\n",
       " ...]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_vocabulary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "de9c68a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([6055,    1, 1397, 5935, 1883,   57,  910,  205, 5018,  681, 7764,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0], dtype=int64),\n",
       " 0)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow\n",
    "dataset = tensorflow.data.Dataset.from_tensor_slices((vectorized_text, y))\n",
    "dataset = dataset.shuffle(18000)\n",
    "dataset.as_numpy_iterator().next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "80efdf7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text     damn thought they had strict gun law germany\n",
       "Label                                               0\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13684df2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
