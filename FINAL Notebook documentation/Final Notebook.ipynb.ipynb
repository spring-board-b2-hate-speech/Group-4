{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "298a83ed",
   "metadata": {},
   "source": [
    "PROJECT:- Hate speech Recognition in online group chat rooms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801840fc",
   "metadata": {},
   "source": [
    "# # Data Preprocessing\n",
    "The first step in our hate speech detection model involves collecting and preprocessing the data. This step is crucial as the quality and cleanliness of the data significantly affect the model's performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414a478a",
   "metadata": {},
   "source": [
    "We use the provided dataset (HateSpeechDetection.csv), which contains text data labeled as hate speech (1) or not hate speech (0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "057979bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Damn I thought they had strict gun laws in Ger...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I dont care about what it stands for or anythi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>It's not a group it's an idea lol</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>So it's not just America!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The dog is a spectacular dancer considering he...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>If ppl dont wear masks you complain... If ppl ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>We should send them All back  to africa</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Checking to see if it's whataboutism from the ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>As a european, I approve this.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Idk which of these groups to join, they're all...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Sometimes the messenger is just as important a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>This is the future we all want.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Wow the monkey calls someone else a monkey lol</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>They are the gypsies of America.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>I know that guy!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Text  Label\n",
       "0   Damn I thought they had strict gun laws in Ger...      0\n",
       "1   I dont care about what it stands for or anythi...      0\n",
       "2                   It's not a group it's an idea lol      0\n",
       "3                           So it's not just America!      0\n",
       "4   The dog is a spectacular dancer considering he...      0\n",
       "5   If ppl dont wear masks you complain... If ppl ...      0\n",
       "6             We should send them All back  to africa      1\n",
       "7   Checking to see if it's whataboutism from the ...      0\n",
       "8                      As a european, I approve this.      0\n",
       "9   Idk which of these groups to join, they're all...      0\n",
       "10  Sometimes the messenger is just as important a...      0\n",
       "11                    This is the future we all want.      0\n",
       "12     Wow the monkey calls someone else a monkey lol      1\n",
       "13                   They are the gypsies of America.      1\n",
       "14                                   I know that guy!      0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv(\"HateSpeechDetection.csv\")\n",
    "data.head(15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "20cacaaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17586</th>\n",
       "      <td>africans should be in a zoo with the other ani...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17587</th>\n",
       "      <td>I wouldn't want my daughter to marry a Chink</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17588</th>\n",
       "      <td>not anymore. they are like the shitty utube no...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17589</th>\n",
       "      <td>Yet still, better for a 750cc to seek a win (o...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17590</th>\n",
       "      <td>people this is new thread due to the impending...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17591</th>\n",
       "      <td>I find rats nicer and cleaner than most Chinese</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17592</th>\n",
       "      <td>Check out this niggar, they hit things like wi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17593</th>\n",
       "      <td>this country has become an absolute shambles, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17594</th>\n",
       "      <td>Me aged 16 = anti-Semitism is bad Me aged 18 =...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17595</th>\n",
       "      <td>so messed up saying blacks don't deserve rights</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Text  Label\n",
       "17586  africans should be in a zoo with the other ani...      1\n",
       "17587       I wouldn't want my daughter to marry a Chink      1\n",
       "17588  not anymore. they are like the shitty utube no...      1\n",
       "17589  Yet still, better for a 750cc to seek a win (o...      0\n",
       "17590  people this is new thread due to the impending...      0\n",
       "17591    I find rats nicer and cleaner than most Chinese      1\n",
       "17592  Check out this niggar, they hit things like wi...      1\n",
       "17593  this country has become an absolute shambles, ...      0\n",
       "17594  Me aged 16 = anti-Semitism is bad Me aged 18 =...      1\n",
       "17595    so messed up saying blacks don't deserve rights      0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2639c66b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17596 entries, 0 to 17595\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Text    17596 non-null  object\n",
      " 1   Label   17596 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 275.1+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be2a486",
   "metadata": {},
   "source": [
    "After observing the dataset, we can infer that we need to clean and transform the raw text data into a format suitable for our  model. This involves several sub-steps:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "920d490f",
   "metadata": {},
   "source": [
    "Removing Extra Spaces: Normalize the spacing in the text to remove any extra spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c59a9dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_extra_spaces(text):\n",
    "    return re.sub(r'\\s+', ' ', text) #the re.sub function replaces one or more whitespace characters (\\s+) with a single space.\n",
    "data['Text'] = data['Text'].apply(remove_extra_spaces)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16839dd9",
   "metadata": {},
   "source": [
    "Remove usernames: Same as for the URL, a username in a text won’t give any valuable information because it won’t be recognized as a word carrying meaning. We will then remove it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0cc30431",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_username(text):\n",
    "    return re.sub(r\"@\\S+\", \"\",text) \n",
    "#We used pattern “@\\S+” -> it suggests string group which starts with ‘@’ and followed by non-whitespace character(\\S), ‘+’ means repeatition of preceding character one or more times\n",
    "\n",
    "data['Text'] = data['Text'].apply(remove_username)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4523437a",
   "metadata": {},
   "source": [
    "Remove Hashtags: Hashtags are hard to apprehend, but usually contain useful information about the context of a text and its content. The problem with hashtags is that the words are all after the other, without a space. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3757241b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17591</th>\n",
       "      <td>I find rats nicer and cleaner than most Chinese</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17592</th>\n",
       "      <td>Check out this niggar, they hit things like wi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17593</th>\n",
       "      <td>this country has become an absolute shambles, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17594</th>\n",
       "      <td>Me aged 16 = anti-Semitism is bad Me aged 18 =...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17595</th>\n",
       "      <td>so messed up saying blacks don't deserve rights</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Text  Label\n",
       "17591    I find rats nicer and cleaner than most Chinese      1\n",
       "17592  Check out this niggar, they hit things like wi...      1\n",
       "17593  this country has become an absolute shambles, ...      0\n",
       "17594  Me aged 16 = anti-Semitism is bad Me aged 18 =...      1\n",
       "17595    so messed up saying blacks don't deserve rights      0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_hashtags(text):\n",
    "    return re.sub(r'#', '', text)\n",
    "# replacing the character(\"#\") with \"\" but not removing the term.\n",
    "\n",
    "data['Text'] = data['Text'].apply(remove_hashtags)\n",
    "data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcdec827",
   "metadata": {},
   "source": [
    "Lowercasing: Convert all text to lowercase to ensure uniformity, as the model should treat \"Hate\" and \"hate\" as the same word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "81013400",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_lower(text):\n",
    "    return text.lower()\n",
    "data['Text'] = data['Text'].apply(text_lower)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d445a83",
   "metadata": {},
   "source": [
    "Removing Punctuation: Strip out punctuation to focus on the words themselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0e4287b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17591</th>\n",
       "      <td>i find rats nicer and cleaner than most chinese</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17592</th>\n",
       "      <td>check out this niggar they hit things like wil...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17593</th>\n",
       "      <td>this country has become an absolute shambles t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17594</th>\n",
       "      <td>me aged 16  antisemitism is bad me aged 18  an...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17595</th>\n",
       "      <td>so messed up saying blacks dont deserve rights</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Text  Label\n",
       "17591    i find rats nicer and cleaner than most chinese      1\n",
       "17592  check out this niggar they hit things like wil...      1\n",
       "17593  this country has become an absolute shambles t...      0\n",
       "17594  me aged 16  antisemitism is bad me aged 18  an...      1\n",
       "17595     so messed up saying blacks dont deserve rights      0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_punctuation(text):\n",
    "    return re.sub(r'[^\\w\\s]', '', text)\n",
    "    #\\w: Represents any alphanumeric character (equivalent to [a-zA-Z0-9_]).\n",
    "    #\\s: Denotes any whitespace character, such as space, tab, or newline.\n",
    "    # so it defines the other than a alphanumeric character followed by a single space, ('^' for negation) remove other characters\n",
    "\n",
    "data['Text'] = data['Text'].apply(remove_punctuation)\n",
    "data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef16c84",
   "metadata": {},
   "source": [
    "Remove URLs: URLs do not give any information when we try to analyze text from words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "049c78a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_url(text):\n",
    "    return re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
    "# it identifies the words starting with http or https or www and ending with a non-white space Character(\\S) then remove it\n",
    "\n",
    "data['Text'] = data['Text'].apply(remove_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a805b418",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4b0ef2ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[damn, i, thought, they, had, strict, gun, law...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[i, dont, care, about, what, it, stands, for, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[its, not, a, group, its, an, idea, lol]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[so, its, not, just, america]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[the, dog, is, a, spectacular, dancer, conside...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17591</th>\n",
       "      <td>[i, find, rats, nicer, and, cleaner, than, mos...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17592</th>\n",
       "      <td>[check, out, this, niggar, they, hit, things, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17593</th>\n",
       "      <td>[this, country, has, become, an, absolute, sha...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17594</th>\n",
       "      <td>[me, aged, 16, antisemitism, is, bad, me, aged...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17595</th>\n",
       "      <td>[so, messed, up, saying, blacks, dont, deserve...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17596 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Text  Label\n",
       "0      [damn, i, thought, they, had, strict, gun, law...      0\n",
       "1      [i, dont, care, about, what, it, stands, for, ...      0\n",
       "2               [its, not, a, group, its, an, idea, lol]      0\n",
       "3                          [so, its, not, just, america]      0\n",
       "4      [the, dog, is, a, spectacular, dancer, conside...      0\n",
       "...                                                  ...    ...\n",
       "17591  [i, find, rats, nicer, and, cleaner, than, mos...      1\n",
       "17592  [check, out, this, niggar, they, hit, things, ...      1\n",
       "17593  [this, country, has, become, an, absolute, sha...      0\n",
       "17594  [me, aged, 16, antisemitism, is, bad, me, aged...      1\n",
       "17595  [so, messed, up, saying, blacks, dont, deserve...      0\n",
       "\n",
       "[17596 rows x 2 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "data['Text'] = data['Text'].apply(word_tokenize)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9607602",
   "metadata": {},
   "source": [
    "Data claening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6904d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Remove rows with missing values from the DataFrame\n",
    "cleaned_data = train_data.dropna()\n",
    "\n",
    "# Separate features and target variable\n",
    "features = cleaned_data['text']\n",
    "target = cleaned_data['label']\n",
    "\n",
    "# Print the shape of the features and target arrays\n",
    "print(\"Shape of features (X):\", features.shape)\n",
    "print(\"Shape of target (y):\", target.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4102880",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "training_features, testing_features, training_labels, testing_labels = train_test_split(\n",
    "    features, target, test_size=0.2, random_state=42, stratify=target\n",
    ")\n",
    "\n",
    "# Print the shapes of the resulting datasets\n",
    "print(\"Training features shape:\", training_features.shape)\n",
    "print(\"Testing features shape:\", testing_features.shape)\n",
    "print(\"Training labels shape:\", training_labels.shape)\n",
    "print(\"Testing labels shape:\", testing_labels.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e29f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Initialize the TF-IDF Vectorizer with specified parameters\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=10000, ngram_range=(1, 2))\n",
    "\n",
    "# Fit and transform the training data\n",
    "X_train_tfidf_matrix = tfidf_vectorizer.fit_transform(training_features)\n",
    "\n",
    "# Transform the test data based on the fitted TF-IDF vectorizer\n",
    "X_test_tfidf_matrix = tfidf_vectorizer.transform(testing_features)\n",
    "\n",
    "# Print shapes of TF-IDF matrices for training and testing sets\n",
    "print(\"Shape of training TF-IDF matrix:\", X_train_tfidf_matrix.shape)\n",
    "print(\"Shape of testing TF-IDF matrix:\", X_test_tfidf_matrix.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac366da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Initialize SMOTE for handling class imbalance\n",
    "smote_resampler = SMOTE(random_state=42)\n",
    "\n",
    "# Apply SMOTE to the training data to generate synthetic samples\n",
    "X_resampled_features, y_resampled_labels = smote_resampler.fit_resample(X_train_tfidf_matrix, training_labels)\n",
    "\n",
    "# Display the distribution of the resampled labels\n",
    "print(\"Resampled label distribution:\\n\", pd.Series(y_resampled_labels).value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1f3f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Initialize the Logistic Regression model\n",
    "logistic_regression_model = LogisticRegression()\n",
    "\n",
    "# Train the model using the resampled training data\n",
    "logistic_regression_model.fit(X_resampled_features, y_resampled_labels)\n",
    "\n",
    "# Optional: Print a message confirming that the model has been trained\n",
    "print(\"Logistic Regression model has been trained successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50b80e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Create an instance of the RandomForestClassifier\n",
    "random_forest_clf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Optional: Print a message indicating the Random Forest model has been initialized\n",
    "print(\"Random Forest Classifier has been initialized.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eacdccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Initialize the Random Forest Classifier with a fixed random seed\n",
    "rf_classifier = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Train the Random Forest model using the resampled data\n",
    "rf_classifier.fit(X_resampled_features, y_resampled_labels)\n",
    "\n",
    "# Optional: Print a message confirming that the Random Forest model has been trained\n",
    "print(\"Random Forest Classifier has been trained successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d20170d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Create an instance of the RandomForestClassifier with a fixed random seed for reproducibility\n",
    "forest_classifier = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Optional: Print a message confirming the classifier initialization\n",
    "print(\"RandomForestClassifier instance has been created.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06991d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model's performance on the test set\n",
    "test_accuracy = rf_classifier.score(X_test_tfidf_matrix, testing_labels)\n",
    "\n",
    "# Print the accuracy of the Random Forest Classifier on the test data\n",
    "print(f\"Accuracy of the Random Forest Classifier on the test set: {test_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab012e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Make predictions using the trained Random Forest model\n",
    "predicted_labels = rf_classifier.predict(X_test_tfidf_matrix)\n",
    "\n",
    "# Compute and print the confusion matrix\n",
    "conf_matrix = confusion_matrix(testing_labels, predicted_labels)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "\n",
    "# Generate and print the classification report\n",
    "class_report = classification_report(testing_labels, predicted_labels)\n",
    "print(\"Classification Report:\\n\", class_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f8964a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Generate predictions on the test set using the trained Random Forest model\n",
    "predicted_labels = rf_classifier.predict(X_test_tfidf_matrix)\n",
    "\n",
    "# Create a classification report for the predictions\n",
    "classification_summary = classification_report(testing_labels, predicted_labels)\n",
    "\n",
    "# Print the classification report\n",
    "print(\"Classification Report:\\n\", classification_summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a80cab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [100, 150,200,300,350,400], \n",
    "    'max_features': [1,2,'sqrt', 'log2', None], \n",
    "    'max_depth': [4, 6, 10,15,20], \n",
    "    'max_leaf_nodes': [2, 4, 6,12,20]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88ca48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV with the Random Forest Classifier and parameter grid\n",
    "grid_search = GridSearchCV(estimator=rf_classifier, \n",
    "                           param_grid=param_grid, \n",
    "                           cv=5, \n",
    "                           verbose=2, \n",
    "                           n_jobs=-1)\n",
    "\n",
    "# Optionally, fit GridSearchCV to the training data\n",
    "grid_search.fit(X_resampled_features, y_resampled_labels)\n",
    "\n",
    "# Print the best parameters found by GridSearchCV\n",
    "print(\"Best parameters found:\\n\", grid_search.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5fe0b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Make predictions on the test set using the best model from GridSearchCV\n",
    "predicted_labels_best = grid_search.predict(X_test_tfidf_matrix)\n",
    "\n",
    "# Generate and print the classification report\n",
    "report_summary = classification_report(testing_labels, predicted_labels_best)\n",
    "print(\"Classification Report:\\n\", report_summary)\n",
    "\n",
    "# Compute and print the confusion matrix\n",
    "confusion_mat = confusion_matrix(testing_labels, predicted_labels_best)\n",
    "print(\"Confusion Matrix:\\n\", confusion_mat)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c137a62",
   "metadata": {},
   "source": [
    "Data balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab71ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import re\n",
    "\n",
    "# Assume train_data is already loaded into a pandas DataFrame\n",
    "# train_data = pd.read_csv('path_to_your_csv.csv')\n",
    "\n",
    "# Preprocess text data: Remove NaNs, clean text, and split data\n",
    "train_data = train_data.dropna(subset=['text', 'label'])\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    text = re.sub(r'@\\w+', '', text)\n",
    "    text = re.sub(r'#\\w+', '', text)\n",
    "    text = re.sub(r'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804365e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Load your DataFrame (df)\n",
    "# df = pd.read_csv('path_to_your_csv.csv')\n",
    "\n",
    "# Count the number of columns in the DataFrame\n",
    "column_count = df.shape[1]\n",
    "print(f\"Number of columns: {column_count}\")\n",
    "\n",
    "# Function to preprocess text\n",
    "def preprocess_text(text):\n",
    "    # Remove special characters and numbers\n",
    "    cleaned_text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    # Convert to lowercase\n",
    "    cleaned_text = cleaned_text.lower()\n",
    "    return cleaned_text\n",
    "\n",
    "# Apply preprocessing to the 'comment' column\n",
    "df['processed_comment'] = df['comment'].apply(preprocess_text)\n",
    "\n",
    "# Split the dataset into features (X) and target (y)\n",
    "X = df['processed_comment']\n",
    "y = df['label']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e485ece0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Vectorize the text data (convert text to numerical features)\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=1000)  # Adjust max_features as needed\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(X)\n",
    "\n",
    "# Print the shape of the data before sampling\n",
    "print(f\"Shape of data before sampling: {X_tfidf.shape}, {y.shape}\")\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train_tfidf, X_test_tfidf, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0139f815",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import re\n",
    "\n",
    "# Load your DataFrame (df)\n",
    "# df = pd.read_csv('path_to_your_csv.csv')\n",
    "\n",
    "# Count the number of columns in the DataFrame\n",
    "column_count = df.shape[1]\n",
    "print(f\"Number of columns: {column_count}\")\n",
    "\n",
    "# Function to preprocess text\n",
    "def preprocess_text(text):\n",
    "    # Remove special characters and numbers\n",
    "    cleaned_text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    # Convert to lowercase\n",
    "    cleaned_text = cleaned_text.lower()\n",
    "    return cleaned_text\n",
    "\n",
    "# Apply preprocessing to the 'comment' column\n",
    "df['processed_comment'] = df['comment'].apply(preprocess_text)\n",
    "\n",
    "# Split the dataset into features (X) and target (y)\n",
    "X = df['processed_comment']\n",
    "y = df['label']\n",
    "\n",
    "# Vectorize the text data (convert text to numerical features)\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=1000)  # Adjust max_features as needed\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(X)\n",
    "\n",
    "# Print the shape of the data before sampling\n",
    "print(f\"Shape of data before sampling: {X_tfidf.shape}, {y.shape}\")\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train_tfidf, X_test_tfidf, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Handle class imbalance using RandomOverSampler\n",
    "oversampler = RandomOverSampler(random_state=42)\n",
    "X_resampled, y_resampled = oversampler.fit_resample(X_train_tfidf, y_train)\n",
    "\n",
    "# Train a K-Nearest Neighbors classifier\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_classifier.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = knn_classifier.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate the model after random oversampling\n",
    "print(\"Evaluation after Random Oversampling:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6aba0f9",
   "metadata": {},
   "source": [
    "Feature encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd54cfcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, precision_score, recall_score, f1_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Load the new dataset\n",
    "dataset = pd.read_csv('new_processed_dataset.csv')\n",
    "print(dataset.head())\n",
    "\n",
    "# Drop rows with NaN values in the 'tweet' column\n",
    "dataset = dataset.dropna(subset=['tweet'])\n",
    "\n",
    "# Define the input features and target variable\n",
    "features = dataset['tweet']\n",
    "target = dataset['class']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "features_train, features_test, target_train, target_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Function to display evaluation metrics\n",
    "def display_metrics(actual, predicted):\n",
    "    print(\"Accuracy:\", accuracy_score(actual, predicted))\n",
    "    print(\"Precision:\", precision_score(actual, predicted, average='weighted'))\n",
    "    print(\"Recall:\", recall_score(actual, predicted, average='weighted'))\n",
    "    print(\"F1 Score:\", f1_score(actual, predicted, average='weighted'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "074fde53",
   "metadata": {},
   "source": [
    "Logistic encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ea430a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Create a pipeline for text classification with CountVectorizer and LogisticRegression\n",
    "text_pipeline = Pipeline([\n",
    "    ('vectorizer', CountVectorizer(binary=True, max_features=1000)),\n",
    "    ('classifier', LogisticRegression())\n",
    "])\n",
    "\n",
    "# Fit the pipeline on the training data\n",
    "text_pipeline.fit(features_train, target_train)\n",
    "\n",
    "# Predict on the test data\n",
    "predictions = text_pipeline.predict(features_test)\n",
    "\n",
    "# Output the evaluation metrics\n",
    "print(\"Evaluation using Count Vectorization and Logistic Regression:\")\n",
    "print(\"Accuracy Score:\", accuracy_score(target_test, predictions))\n",
    "print(\"Classification Report:\\n\", classification_report(target_test, predictions))\n",
    "\n",
    "# Function to display additional metrics\n",
    "def show_metrics(actual, predicted):\n",
    "    print(\"Accuracy:\", accuracy_score(actual, predicted))\n",
    "    print(\"Precision:\", precision_score(actual, predicted, average='weighted'))\n",
    "    print(\"Recall:\", recall_score(actual, predicted, average='weighted'))\n",
    "    print(\"F1 Score:\", f1_score(actual, predicted, average='weighted'))\n",
    "\n",
    "# Display additional metrics\n",
    "show_metrics(target_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72770bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "rom sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# TF-IDF Encoding Pipeline\n",
    "pipeline_tfidf = Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer(max_features=1000)),\n",
    "    ('classifier', LogisticRegression())\n",
    "])\n",
    "\n",
    "# Train and evaluate the model\n",
    "pipeline_tfidf.fit(X_train, y_train)\n",
    "y_pred_tfidf = pipeline_tfidf.predict(X_test)\n",
    "print(\"TF-IDF Encoding\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_tfidf))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_tfidf))\n",
    "print_metrics(y_test, y_pred_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a55f559",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class Word2VecTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, vector_size=100, window=5, min_count=1):\n",
    "        self.vector_size = vector_size\n",
    "        self.window = window\n",
    "        self.min_count = min_count\n",
    "        self.model = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        tokenized_X = [tweet.split() for tweet in X]\n",
    "        self.model = Word2Vec(sentences=tokenized_X, vector_size=self.vector_size, window=self.window, min_count=self.min_count)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        def get_word2vec_features(text):\n",
    "            words = text.split()\n",
    "            feature_vector = np.mean([self.model.wv[word] for word in words if word in self.model.wv] or [np.zeros(self.vector_size)], axis=0)\n",
    "            return feature_vector\n",
    "        \n",
    "        return np.array([get_word2vec_features(tweet) for tweet in X])\n",
    "\n",
    "# Word2Vec Encoding Pipeline\n",
    "pipeline_w2v = Pipeline([\n",
    "    ('word2vec', Word2VecTransformer(vector_size=100)),  # We don't set max_features for Word2Vec\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', LogisticRegression(max_iter=1000))\n",
    "])\n",
    "\n",
    "# Train and evaluate the model\n",
    "pipeline_w2v.fit(X_train, y_train)\n",
    "y_pred_w2v = pipeline_w2v.predict(X_test)\n",
    "print(\"Word2Vec Encoding\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_w2v))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_w2v))\n",
    "print_metrics(y_test, y_pred_w2v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e1ff2d",
   "metadata": {},
   "source": [
    "Naivebays encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76aa25dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report, precision_score, recall_score, f1_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from gensim.models import Word2Vec\n",
    "import numpy as np\n",
    "\n",
    "# Load and preprocess data\n",
    "dataset = pd.read_csv('new_processed_dataset.csv')\n",
    "print(dataset.head())\n",
    "\n",
    "# Remove duplicates and handle missing values\n",
    "dataset.drop_duplicates(inplace=True)\n",
    "dataset.dropna(inplace=True)\n",
    "\n",
    "# Define features (X) and target (y)\n",
    "features = dataset['tweet']\n",
    "target = dataset['class']\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "features_train, features_test, target_train, target_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Function to print evaluation metrics\n",
    "def display_metrics(actual, predicted):\n",
    "    print(\"Accuracy:\", accuracy_score(actual, predicted))\n",
    "    print(\"Precision:\", precision_score(actual, predicted, average='weighted'))\n",
    "    print(\"Recall:\", recall_score(actual, predicted, average='weighted'))\n",
    "    print(\"F1 Score:\", f1_score(actual, predicted, average='weighted'))\n",
    "    # Instantiate a Multinomial Naive Bayes classifier pipeline with CountVectorizer\n",
    "nb_pipeline = Pipeline([\n",
    "    ('vectorizer', CountVectorizer(max_features=5000)),\n",
    "    ('classifier', MultinomialNB())\n",
    "])\n",
    "\n",
    "# Train the pipeline on the training data\n",
    "nb_pipeline.fit(features_train, target_train)\n",
    "\n",
    "# Predict on the test data\n",
    "predictions = nb_pipeline.predict(features_test)\n",
    "\n",
    "# Display evaluation metrics\n",
    "print(\"Evaluation Results:\")\n",
    "display_metrics(target_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7499e674",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Create a pipeline for text classification with CountVectorizer and LogisticRegression\n",
    "text_pipeline = Pipeline([\n",
    "    ('vectorizer', CountVectorizer(binary=True, max_features=1000)),\n",
    "    ('classifier', LogisticRegression())\n",
    "])\n",
    "\n",
    "# Fit the pipeline on the training data\n",
    "text_pipeline.fit(features_train, target_train)\n",
    "\n",
    "# Predict on the test data\n",
    "predictions = text_pipeline.predict(features_test)\n",
    "\n",
    "# Output the evaluation metrics\n",
    "print(\"Evaluation using Count Vectorization and Logistic Regression:\")\n",
    "print(\"Accuracy Score:\", accuracy_score(target_test, predictions))\n",
    "print(\"Classification Report:\\n\", classification_report(target_test, predictions))\n",
    "\n",
    "# Function to display additional metrics\n",
    "def show_metrics(actual, predicted):\n",
    "    print(\"Accuracy:\", accuracy_score(actual, predicted))\n",
    "    print(\"Precision:\", precision_score(actual, predicted, average='weighted'))\n",
    "    print(\"Recall:\", recall_score(actual, predicted, average='weighted'))\n",
    "    print(\"F1 Score:\", f1_score(actual, predicted, average='weighted'))\n",
    "\n",
    "# Display additional metrics\n",
    "show_metrics(target_test, predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d9cce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Create a pipeline for text classification with CountVectorizer and Multinomial Naive Bayes\n",
    "text_pipeline = Pipeline([\n",
    "    ('count_vectorizer', CountVectorizer(binary=True, max_features=1000)),\n",
    "    ('naive_bayes', MultinomialNB())\n",
    "])\n",
    "\n",
    "# Train the pipeline using the training dataset\n",
    "text_pipeline.fit(features_train, target_train)\n",
    "\n",
    "# Generate predictions on the test set\n",
    "test_predictions = text_pipeline.predict(features_test)\n",
    "\n",
    "# Print the classification report\n",
    "print(\"Text Classification Evaluation with Naive Bayes:\")\n",
    "print(\"Classification Report:\\n\", classification_report(target_test, test_predictions))\n",
    "\n",
    "# Define a function to print detailed performance metrics\n",
    "def print_performance_metrics(true_labels, predicted_labels):\n",
    "    print(\"Accuracy Score:\", accuracy_score(true_labels, predicted_labels))\n",
    "    print(\"Precision Score:\", precision_score(true_labels, predicted_labels, average='weighted'))\n",
    "    print(\"Recall Score:\", recall_score(true_labels, predicted_labels, average='weighted'))\n",
    "    print(\"F1 Score:\", f1_score(true_labels, predicted_labels, average='weighted'))\n",
    "\n",
    "# Output the detailed performance metrics\n",
    "print_performance_metrics(target_test, test_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548eba7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Create a pipeline for text classification using TF-IDF and Multinomial Naive Bayes\n",
    "tfidf_pipeline = Pipeline([\n",
    "    ('tfidf_vectorizer', TfidfVectorizer(max_features=1000)),\n",
    "    ('naive_bayes_classifier', MultinomialNB())\n",
    "])\n",
    "\n",
    "# Train the pipeline on the training data\n",
    "tfidf_pipeline.fit(features_train, target_train)\n",
    "\n",
    "# Predict the labels for the test set\n",
    "predicted_labels_tfidf = tfidf_pipeline.predict(features_test)\n",
    "\n",
    "# Print the classification report for TF-IDF encoding with Naive Bayes\n",
    "print(\"Evaluation of TF-IDF Encoding with Naive Bayes Classifier:\")\n",
    "print(\"Classification Report:\\n\", classification_report(target_test, predicted_labels_tfidf))\n",
    "\n",
    "# Function to display performance metrics\n",
    "def show_performance_metrics(true_values, predicted_values):\n",
    "    print(\"Accuracy:\", accuracy_score(true_values, predicted_values))\n",
    "    print(\"Precision:\", precision_score(true_values, predicted_values, average='weighted'))\n",
    "    print(\"Recall:\", recall_score(true_values, predicted_values, average='weighted'))\n",
    "    print(\"F1 Score:\", f1_score(true_values, predicted_values, average='weighted'))\n",
    "\n",
    "# Display additional metrics for the TF-IDF pipeline results\n",
    "show_performance_metrics(target_test, predicted_labels_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d92916",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Custom Transformer for Word2Vec\n",
    "class CustomWord2VecTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, vector_size=100, window=5, min_count=1):\n",
    "        self.vector_size = vector_size\n",
    "        self.window = window\n",
    "        self.min_count = min_count\n",
    "        self.word2vec_model = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        tokenized_texts = [text.split() for text in X]\n",
    "        self.word2vec_model = Word2Vec(sentences=tokenized_texts, vector_size=self.vector_size, window=self.window, min_count=self.min_count)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        def compute_feature_vector(text):\n",
    "            tokens = text.split()\n",
    "            vectors = [self.word2vec_model.wv[token] for token in tokens if token in self.word2vec_model.wv]\n",
    "            if not vectors:\n",
    "                return np.zeros(self.vector_size)\n",
    "            return np.mean(vectors, axis=0)\n",
    "        \n",
    "        return np.array([compute_feature_vector(text) for text in X])\n",
    "\n",
    "# Define the pipeline with the Word2Vec transformer and Gaussian Naive Bayes\n",
    "w2v_pipeline = Pipeline([\n",
    "    ('word2vec_transformer', CustomWord2VecTransformer(vector_size=100)),  # Reduced vector size for quicker processing\n",
    "    ('naive_bayes_classifier', GaussianNB())\n",
    "])\n",
    "\n",
    "# Fit the pipeline on the training data\n",
    "w2v_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels for the test set\n",
    "predicted_labels_w2v = w2v_pipeline.predict(X_test)\n",
    "\n",
    "# Print the classification report for the Word2Vec model\n",
    "print(\"Word2Vec Encoding with Naive Bayes Classifier:\")\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, predicted_labels_w2v))\n",
    "\n",
    "# Function to display performance metrics\n",
    "def display_metrics(true_labels, predicted_labels):\n",
    "    print(\"Accuracy:\", accuracy_score(true_labels, predicted_labels))\n",
    "    print(\"Precision:\", precision_score(true_labels, predicted_labels, average='weighted'))\n",
    "    print(\"Recall:\", recall_score(true_labels, predicted_labels, average='weighted'))\n",
    "    print(\"F1 Score:\", f1_score(true_labels, predicted_labels, average='weighted'))\n",
    "\n",
    "# Display detailed performance metrics\n",
    "display_metrics(y_test, predicted_labels_w2v)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b865ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Define the pipeline for Term Frequency encoding with Naive Bayes\n",
    "tf_pipeline = Pipeline([\n",
    "    ('tf_vectorizer', CountVectorizer(max_features=1000)),  # Convert text data into term frequency features\n",
    "    ('naive_bayes', MultinomialNB())  # Classifier\n",
    "])\n",
    "\n",
    "# Fit the pipeline on the training data\n",
    "tf_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels for the test data\n",
    "predicted_labels_tf = tf_pipeline.predict(X_test)\n",
    "\n",
    "# Print the classification report for the Term Frequency encoding model\n",
    "print(\"Term Frequency Encoding with Naive Bayes Classifier:\")\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, predicted_labels_tf))\n",
    "\n",
    "# Function to display additional performance metrics\n",
    "def display_performance_metrics(true_labels, predicted_labels):\n",
    "    print(\"Accuracy:\", accuracy_score(true_labels, predicted_labels))\n",
    "    print(\"Precision:\", precision_score(true_labels, predicted_labels, average='weighted'))\n",
    "    print(\"Recall:\", recall_score(true_labels, predicted_labels, average='weighted'))\n",
    "    print(\"F1 Score:\", f1_score(true_labels, predicted_labels, average='weighted'))\n",
    "\n",
    "# Show detailed performance metrics\n",
    "display_performance_metrics(y_test, predicted_labels_tf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c913a3b",
   "metadata": {},
   "source": [
    "Embedding Techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e246022",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word Tokenization with NLTK\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Ensure text column is of type string\n",
    "train_data['text'] = train_data['text'].astype(str)\n",
    "\n",
    "# Download required NLTK resources (if not already downloaded)\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Apply word tokenization to each text entry in the DataFrame\n",
    "train_data['tokenized_text'] = train_data['text'].apply(word_tokenize)\n",
    "\n",
    "# Display the DataFrame with the new tokenized_text column\n",
    "print(train_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69ccc48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Drop rows with missing values in the 'text' column\n",
    "train_data.dropna(subset=['text'], inplace=True)\n",
    "\n",
    "# Function to compute TF-IDF embeddings\n",
    "def compute_tfidf_embeddings(corpus):\n",
    "    tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
    "    tfidf_embeddings = tfidf_vectorizer.fit_transform(corpus)\n",
    "    return tfidf_embeddings\n",
    "\n",
    "# Extract text data and compute TF-IDF embeddings\n",
    "text_data = train_data['text'].values\n",
    "tfidf_embeddings = compute_tfidf_embeddings(text_data)\n",
    "\n",
    "# Print the TF-IDF embeddings\n",
    "print(tfidf_embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58a7fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Step 1: TF-IDF Encoding\n",
    "def compute_tfidf_embeddings(corpus):\n",
    "    tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
    "    tfidf_embeddings = tfidf_vectorizer.fit_transform(corpus)\n",
    "    return tfidf_embeddings\n",
    "\n",
    "# Extract text and target variable\n",
    "texts = train_data['text'].values\n",
    "target = train_data['hd'].values\n",
    "\n",
    "# Compute TF-IDF embeddings\n",
    "tfidf_embeddings = compute_tfidf_embeddings(texts)\n",
    "\n",
    "# Step 2: Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(tfidf_embeddings, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 3: Train Random Forest model\n",
    "random_forest_model = RandomForestClassifier(random_state=42)\n",
    "random_forest_model.fit(X_train, y_train)\n",
    "\n",
    "# Step 4: Predictions and Evaluation\n",
    "y_pred = random_forest_model.predict(X_test)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed631fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Extract text data from the training DataFrame\n",
    "text_data = train_data['text'].values\n",
    "\n",
    "# Replace NaN values with empty strings\n",
    "text_data = np.where(pd.isnull(text_data), '', text_data)\n",
    "\n",
    "# Tokenize the text data\n",
    "tokenized_texts = [word_tokenize(text) for text in text_data]\n",
    "\n",
    "# Train a Word2Vec model on the tokenized texts\n",
    "word2vec_model = Word2Vec(sentences=tokenized_texts, vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "# Function to compute average Word2Vec embeddings for each document\n",
    "def average_word2vec(tokens, model, vocab, vector_dim):\n",
    "    vec_sum = np.zeros((vector_dim,), dtype=\"float32\")\n",
    "    num_tokens = 0\n",
    "    for token in tokens:\n",
    "        if token in vocab:\n",
    "            num_tokens += 1\n",
    "            vec_sum = np.add(vec_sum, model.wv[token])\n",
    "    if num_tokens > 0:\n",
    "        vec_sum = np.divide(vec_sum, num_tokens)\n",
    "    return vec_sum\n",
    "\n",
    "# Generate average embeddings for each text in the training set\n",
    "vocabulary_set = set(word2vec_model.wv.index_to_key)\n",
    "text_embeddings = np.array([average_word2vec(tokens, word2vec_model, vocabulary_set, 100) for tokens in tokenized_texts])\n",
    "\n",
    "# Print the resulting embeddings\n",
    "print(text_embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85242f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Display the first two rows of the DataFrame and its info\n",
    "print(train_data.head(2))\n",
    "train_data.info()\n",
    "\n",
    "# Ensure 'label' column is treated as string type\n",
    "train_data['text'] = train_data['label'].astype(str)\n",
    "\n",
    "# Initialize OneHotEncoder\n",
    "encoder = OneHotEncoder(sparse=False, drop='first')\n",
    "\n",
    "# Fit and transform the 'label' column to one-hot encoded format\n",
    "encoded_labels = encoder.fit_transform(train_data[['label']])\n",
    "\n",
    "# Print the one-hot encoded array\n",
    "print(encoded_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df4be4c",
   "metadata": {},
   "source": [
    "Model Techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426fb122",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "import re\n",
    "\n",
    "# Load your DataFrame (df)\n",
    "# df = pd.read_csv('path_to_your_csv.csv')\n",
    "\n",
    "# Count the number of columns in the DataFrame\n",
    "column_count = df.shape[1]\n",
    "print(f\"Number of columns: {column_count}\")\n",
    "\n",
    "# Function to preprocess text\n",
    "def preprocess_text(text):\n",
    "    # Remove special characters and numbers\n",
    "    cleaned_text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    # Convert to lowercase\n",
    "    cleaned_text = cleaned_text.lower()\n",
    "    return cleaned_text\n",
    "\n",
    "# Apply preprocessing to the 'comment' column\n",
    "df['processed_comment'] = df['comment'].apply(preprocess_text)\n",
    "\n",
    "# Split the dataset into features (X) and target (y)\n",
    "X = df['processed_comment']\n",
    "y = df['label']\n",
    "\n",
    "# Vectorize the text data (convert text to numerical features)\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=1000)  # Adjust max_features as needed\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(X)\n",
    "\n",
    "# Print the shape of the data before sampling\n",
    "print(f\"Shape of data before sampling: {X_tfidf.shape}, {y.shape}\")\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train_tfidf, X_test_tfidf, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Handle class imbalance using RandomOverSampler\n",
    "oversampler = RandomOverSampler(random_state=42)\n",
    "X_resampled, y_resampled = oversampler.fit_resample(X_train_tfidf, y_train)\n",
    "\n",
    "# Train a Decision Tree classifier\n",
    "decision_tree_classifier = DecisionTreeClassifier(random_state=42)\n",
    "decision_tree_classifier.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = decision_tree_classifier.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Evaluation after Random Oversampling:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b882db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "import re\n",
    "\n",
    "# Load your DataFrame (data)\n",
    "# data = pd.read_csv('path_to_your_csv.csv')\n",
    "\n",
    "# Count the number of columns in the DataFrame\n",
    "column_count = data.shape[1]\n",
    "print(f\"Number of columns: {column_count}\")\n",
    "\n",
    "# Assuming the last column is the label and the rest are TF-IDF features\n",
    "X = data.iloc[:, :-1]  # All columns except the last one\n",
    "y = data.iloc[:, -1]   # The last column\n",
    "\n",
    "# Print the shape of the data before sampling\n",
    "print(f\"Shape of data before sampling: {X.shape}, {y.shape}\")\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Handle class imbalance using RandomOverSampler\n",
    "oversampler = RandomOverSampler(random_state=42)\n",
    "X_resampled, y_resampled = oversampler.fit_resample(X_train, y_train)\n",
    "\n",
    "# Train a Decision Tree classifier\n",
    "decision_tree_classifier = DecisionTreeClassifier(random_state=42)\n",
    "decision_tree_classifier.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = decision_tree_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Evaluation after Random Oversampling:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee47d9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "# Assuming 'data' is your DataFrame and it contains TF-IDF features and the label as the last column\n",
    "\n",
    "# Count the number of columns in the DataFrame\n",
    "column_count = data.shape[1]\n",
    "print(f\"Number of columns: {column_count}\")\n",
    "\n",
    "# Separate features and labels\n",
    "X = data.iloc[:, :-1]  # All columns except the last one\n",
    "y = data.iloc[:, -1]   # The last column\n",
    "\n",
    "# Print the shape of the data before sampling\n",
    "print(f\"Shape of data before sampling: {X.shape}, {y.shape}\")\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Handle class imbalance using RandomOverSampler\n",
    "oversampler = RandomOverSampler(random_state=42)\n",
    "X_resampled, y_resampled = oversampler.fit_resample(X_train, y_train)\n",
    "\n",
    "# Train a Decision Tree classifier\n",
    "decision_tree_classifier = DecisionTreeClassifier(random_state=42)\n",
    "decision_tree_classifier.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = decision_tree_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Evaluation after Random Oversampling:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff68737",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "# Assuming 'data' is your DataFrame and it contains TF-IDF features and the label as the last column\n",
    "\n",
    "# Count the number of columns in the DataFrame\n",
    "column_count = data.shape[1]\n",
    "print(f\"Number of columns: {column_count}\")\n",
    "\n",
    "# Separate features and labels\n",
    "X = data.iloc[:, :-1]  # All columns except the last one\n",
    "y = data.iloc[:, -1]   # The last column\n",
    "\n",
    "# Print the shape of the data before sampling\n",
    "print(f\"Shape of data before sampling: {X.shape}, {y.shape}\")\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Handle class imbalance using RandomOverSampler\n",
    "oversampler = RandomOverSampler(random_state=42)\n",
    "X_resampled, y_resampled = oversampler.fit_resample(X_train, y_train)\n",
    "\n",
    "# Instantiate and train a Decision Tree classifier\n",
    "decision_tree =\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8451a75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the labels for the test set\n",
    "y_pred = decision_tree.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00dcd6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "# Assuming 'data' is your DataFrame and it contains TF-IDF features and the label as the last column\n",
    "\n",
    "# Count the number of columns in the DataFrame\n",
    "column_count = data.shape[1]\n",
    "print(f\"Number of columns: {column_count}\")\n",
    "\n",
    "# Separate features and labels\n",
    "X = data.iloc[:, :-1]  # All columns except the last one\n",
    "y = data.iloc[:, -1]   # The last column\n",
    "\n",
    "# Print the shape of the data before sampling\n",
    "print(f\"Shape of data before sampling: {X.shape}, {y.shape}\")\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Handle class imbalance using RandomOverSampler\n",
    "oversampler = RandomOverSampler(random_state=42)\n",
    "X_resampled, y_resampled = oversampler.fit_resample(X_train, y_train)\n",
    "\n",
    "# Instantiate and train a Decision Tree classifier\n",
    "decision_tree = DecisionTreeClassifier(random_state=42)\n",
    "decision_tree.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = decision_tree.predict(X_test)\n",
    "\n",
    "# Evaluate the classifier\n",
    "print(\"Evaluation after Random Oversampling:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b21cc6e",
   "metadata": {},
   "source": [
    "Random forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad93d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Load dataset\n",
    "data = pd.read_csv('new_processed_dataset.csv')\n",
    "print(data.head())\n",
    "\n",
    "# Handle any potential issues with data formats (e.g., strings that need to be converted)\n",
    "# This assumes that some columns might need conversion from string representations of lists or dictionaries\n",
    "data['features'] = data['features'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\n",
    "\n",
    "# Define features and target variable\n",
    "X = data['tweet']  # Assuming 'tweet' contains the text data\n",
    "y = data['class']  # Assuming 'class' contains the labels\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a pipeline that includes TF-IDF vectorization and Random Forest classification\n",
    "text_clf_pipeline = make_pipeline(\n",
    "    TfidfVectorizer(max_features=1000),  # Convert text data to TF-IDF features\n",
    "    RandomForestClassifier(random_state=42)  # Classifier\n",
    ")\n",
    "\n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832255b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset from the specified CSV file\n",
    "df = pd.read_csv('/content/cleaned_dataset_combined (2).csv')\n",
    "\n",
    "# Display the first few rows of the DataFrame to verify successful loading\n",
    "print(\"Displaying the first few rows of the DataFrame:\")\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8402edf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert string representation of list to actual list\n",
    "df['tweet_tokens'] = df['tweet_tokens'].apply(ast.literal_eval)\n",
    "\n",
    "# Display the first few rows to verify\n",
    "print(\"\\nDataFrame after converting tweet_tokens to lists:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea066991",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('/content/cleaned_dataset_combined (2).csv')\n",
    "\n",
    "# Define feature and target variables\n",
    "X = df[['tweet_tokens']]\n",
    "y = df['class']\n",
    "\n",
    "# Convert list of tokens into a single string for each row\n",
    "# Assuming 'tweet_tokens' is a column where each entry is a list of tokens\n",
    "X['tweet_tokens'] = X['tweet_tokens'].apply(lambda tokens: ' '.join(eval(tokens)) if isinstance(tokens, str) else ' '.join(tokens))\n",
    "\n",
    "# Verify the transformation\n",
    "print(\"Transformed DataFrame:\")\n",
    "print(X.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aec4e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('/content/cleaned_dataset_combined (2).csv')\n",
    "\n",
    "# Define feature and target variables\n",
    "X = df[['tweet_tokens']]\n",
    "y = df['class']\n",
    "\n",
    "# Convert list of tokens into a single string for each row\n",
    "# If 'tweet_tokens' is a string representation of a list, use eval to convert it\n",
    "X['tweet_tokens'] = X['tweet_tokens'].apply(lambda tokens: ' '.join(eval(tokens)) if isinstance(tokens, str) else ' '.join(tokens))\n",
    "\n",
    "# Create a ColumnTransformer to apply TfidfVectorizer to the 'tweet_tokens' column\n",
    "column_transformer = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('tfidf', TfidfVectorizer(), 'tweet_tokens')  # Apply TF-IDF vectorization\n",
    "    ],\n",
    "    remainder='passthrough'  # Keep other columns unchanged (though there are none in this case)\n",
    ")\n",
    "\n",
    "# Transform the feature data\n",
    "X_transformed = column_transformer.fit_transform(X)\n",
    "\n",
    "# Output the shape of the transformed data to verify\n",
    "print(\"Shape of the transformed feature data:\")\n",
    "print(X_transformed.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034b4266",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('/content/cleaned_dataset_combined (2).csv')\n",
    "\n",
    "# Define feature and target variables\n",
    "X = df[['tweet_tokens']]\n",
    "y = df['class']\n",
    "\n",
    "# Convert list of tokens into a single string for each row\n",
    "X['tweet_tokens'] = X['tweet_tokens'].apply(lambda tokens: ' '.join(eval(tokens)) if isinstance(tokens, str) else ' '.join(tokens))\n",
    "\n",
    "# Create a ColumnTransformer to apply TfidfVectorizer to the 'tweet_tokens' column\n",
    "column_transformer = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('tfidf', TfidfVectorizer(), 'tweet_tokens')  # Apply TF-IDF vectorization\n",
    "    ],\n",
    "    remainder='passthrough'  # Keep other columns unchanged (though there are none in this case)\n",
    ")\n",
    "\n",
    "# Create a Random Forest classifier pipeline\n",
    "pipeline = make_pipeline(column_transformer, RandomForestClassifier(random_state=42))\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Display the first few rows of the training data and target\n",
    "print(\"\\nTraining Data:\")\n",
    "print(X_train.head())\n",
    "print(\"\\nTraining Target:\")\n",
    "print(y_train.head())\n",
    "\n",
    "# Train the model\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Display classification report\n",
    "from sklearn.metrics import classification_report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3dd89a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('/content/cleaned_dataset_combined (2).csv')\n",
    "\n",
    "# Define feature and target variables\n",
    "X = df[['tweet_tokens']]\n",
    "y = df['class']\n",
    "\n",
    "# Convert list of tokens into a single string for each row\n",
    "X['tweet_tokens'] = X['tweet_tokens'].apply(lambda tokens: ' '.join(eval(tokens)) if isinstance(tokens, str) else ' '.join(tokens))\n",
    "\n",
    "# Create a ColumnTransformer to apply TfidfVectorizer to the 'tweet_tokens' column\n",
    "column_transformer = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('tfidf', TfidfVectorizer(), 'tweet_tokens')  # Apply TF-IDF vectorization\n",
    "    ],\n",
    "    remainder='passthrough'  # Keep other columns unchanged (though there are none in this case)\n",
    ")\n",
    "\n",
    "# Create a Random Forest classifier pipeline\n",
    "pipeline = make_pipeline(column_transformer, RandomForestClassifier(random_state=42))\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = pipeline.score(X_test, y_test)\n",
    "print(f'\\nAccuracy: {accuracy:.4f}')\n",
    "\n",
    "# Predict the test set results\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Print classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c50f06de",
   "metadata": {},
   "source": [
    "Bert_with_Lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e824fbc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing essential libraries for data manipulation, machine learning, and NLP\n",
    "import pandas as pd  # Data manipulation and analysis\n",
    "import numpy as np  # Numerical computing\n",
    "from tqdm import tqdm  # Progress bars for loops\n",
    "from transformers import BertTokenizer, BertModel  # BERT tokenizer and model for NLP\n",
    "import torch  # PyTorch for tensor computation and model handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671b0438",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the pandas library\n",
    "import pandas as pd\n",
    "\n",
    "# Reading the CSV file into a pandas DataFrame\n",
    "file_path = \"/content/ghc_train.csv\"  # Path to the CSV file\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows of the DataFrame to verify successful loading\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294b96ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Fill any missing values in the 'text' column with an empty string\n",
    "df['text'] = df['text'].fillna('')\n",
    "\n",
    "# Define the features (X) and the target variable (y)\n",
    "X = df['text']\n",
    "y = df['label']\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "# 20% of the data is used for testing, and 80% for training\n",
    "# Stratify ensures that each split maintains the proportion of classes in the target variable\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "# Display the size of the training and testing sets\n",
    "print(f\"Training set size: {len(X_train)}\")\n",
    "print(f\"Testing set size: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a99526",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  # For numerical operations and array manipulations\n",
    "import tensorflow as tf  # TensorFlow library for building and training neural networks\n",
    "from tensorflow.keras.models import Sequential  # Sequential model type for Keras\n",
    "from tensorflow.keras.layers import Dense, LSTM, Bidirectional, Dropout  # Layers used in the model\n",
    "from tensorflow.keras.callbacks import EarlyStopping  # Callback for early stopping during training\n",
    "from sklearn.utils.class_weight import compute_class_weight  # Function to compute class weights for imbalanced data\n",
    "from sklearn.metrics import confusion_matrix, classification_report  # Metrics for evaluating model performance\n",
    "import seaborn as sns  # For creating statistical graphics\n",
    "import matplotlib.pyplot as plt  # For plotting data and evaluation results\n",
    "from transformers import BertTokenizer, TFBertModel  # BERT tokenizer and model from Hugging Face\n",
    "\n",
    "# Initializing the BERT tokenizer with the pre-trained 'bert-base-uncased' model\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Initializing the BERT model with the pre-trained 'bert-base-uncased' model\n",
    "bert_model = TFBertModel.from_pretrained('bert-base-uncased')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242ca308",
   "metadata": {},
   "source": [
    "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
    "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
    "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
    "You will be able to reuse this secret in all of your notebooks.\n",
    "Please note that authentication is recommended but still optional to access public models or datasets.\n",
    "  warnings.warn(\n",
    "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]\n",
    "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]\n",
    "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]\n",
    "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
    "  warnings.warn(\n",
    "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]\n",
    "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]\n",
    "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias']\n",
    "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
    "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
    "All the weights of TFBertModel were initialized from the PyTorch model.\n",
    "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da75b6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to encode text data using a BERT tokenizer\n",
    "def encode_texts(texts, tokenizer, max_length=100):\n",
    "    \"\"\"\n",
    "    Encode a list of texts using the BERT tokenizer.\n",
    "\n",
    "    Parameters:\n",
    "    texts (pd.Series): Series of text data to encode.\n",
    "    tokenizer (BertTokenizer): Pre-trained BERT tokenizer.\n",
    "    max_length (int): Maximum length of tokenized sequences.\n",
    "\n",
    "    Returns:\n",
    "    dict: Dictionary containing input_ids and attention_mask tensors.\n",
    "    \"\"\"\n",
    "    encodings = tokenizer(\n",
    "        texts.tolist(),          # Convert Series to list of texts\n",
    "        truncation=True,         # Truncate sequences longer than max_length\n",
    "        padding='max_length',    # Pad sequences to max_length\n",
    "        max_length=max_length,   # Maximum length of the sequences\n",
    "        return_tensors='tf'      # Return TensorFlow tensors\n",
    "    )\n",
    "    return encodings\n",
    "\n",
    "# Encoding the training and testing text data with a maximum length of 50\n",
    "X_train_encodings = encode_texts(X_train, tokenizer, max_length=50)\n",
    "X_test_encodings = encode_texts(X_test, tokenizer, max_length=50)\n",
    "\n",
    "# Function to get BERT embeddings from encoded text data\n",
    "def get_bert_embeddings(encodings, bert_model):\n",
    "    \"\"\"\n",
    "    Obtain BERT embeddings for the encoded text data.\n",
    "     Parameters:\n",
    "    encodings (dict): Encoded text data containing input_ids and attention_mask.\n",
    "    bert_model (TFBertModel): Pre-trained BERT model.\n",
    "\n",
    "    Returns:\n",
    "    tf.Tensor: Tensor containing BERT embeddings.\n",
    "    \"\"\"\n",
    "    outputs = bert_model(\n",
    "        encodings['input_ids'],    # Input token IDs\n",
    "        attention_mask=encodings['attention_mask']  # Attention mask\n",
    "    )\n",
    "    return outputs.last_hidden_state  # Return the embeddings from the last hidden state\n",
    "\n",
    "# Setting the batch size for processing\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8ee6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List to store BERT embeddings for the training data\n",
    "X_train_embeddings = []\n",
    "\n",
    "# Process the training data in batches to get BERT embeddings\n",
    "for i in range(0, len(X_train_encodings['input_ids']), batch_size):\n",
    "    # Create a batch of encodings\n",
    "    batch_encodings = {key: val[i:i+batch_size] for key, val in X_train_encodings.items()}\n",
    "    # Get BERT embeddings for the current batch\n",
    "    batch_embeddings = get_bert_embeddings(batch_encodings, bert_model)\n",
    "    # Append the batch embeddings to the list\n",
    "    X_train_embeddings.append(batch_embeddings)\n",
    "\n",
    "# Concatenate all the batch embeddings into a single tensor\n",
    "X_train_embeddings = tf.concat(X_train_embeddings, axis=0)\n",
    "\n",
    "# List to store BERT embeddings for the testing data\n",
    "X_test_embeddings = []\n",
    "\n",
    "# Process the testing data in batches to get BERT embeddings\n",
    "for i in range(0, len(X_test_encodings['input_ids']), batch_size):\n",
    "    # Create a batch of encodings\n",
    "    batch_encodings = {key: val[i:i+batch_size] for key, val in X_test_encodings.items()}\n",
    "    # Get BERT embeddings for the current batch\n",
    "    batch_embeddings = get_bert_embeddings(batch_encodings, bert_model)\n",
    "    # Append the batch embeddings to the list\n",
    "    X_test_embeddings.append(batch_embeddings)\n",
    "\n",
    "# Concatenate all the batch embeddings into a single tensor\n",
    "X_test_embeddings = tf.concat(X_test_embeddings, axis=0)\n",
    "\n",
    "# Compute class weights to handle class imbalance\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "\n",
    "# Convert class weights to a dictionary format required by TensorFlow\n",
    "class_weights_dict = dict(enumerate(class_weights))\n",
    "\n",
    "# Print class weights for verification\n",
    "print(\"Class weights:\", class_weights_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c568ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Bidirectional, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the model\n",
    "model = Sequential()\n",
    "\n",
    "# Adding a bidirectional LSTM layer with 256 units, returning sequences\n",
    "model.add(Bidirectional(LSTM(units=256, return_sequences=True, input_shape=(X_train_embeddings.shape[1], X_train_embeddings.shape[2]))))\n",
    "\n",
    "# Adding dropout to prevent overfitting\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# Adding another bidirectional LSTM layer with 64 units, returning sequences\n",
    "model.add(Bidirectional(LSTM(units=64, return_sequences=True)))\n",
    "\n",
    "# Adding dropout to prevent overfitting\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "# Adding another bidirectional LSTM layer with 64 units, not returning sequences\n",
    "model.add(Bidirectional(LSTM(units=64)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Adding a dense layer with 64 units and ReLU activation function\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Adding the final dense layer with 1 unit and sigmoid activation function for binary classification\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Define early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train_embeddings, y_train, epochs=5, batch_size=batch_size,\n",
    "                    validation_data=(X_test_embeddings, y_test),\n",
    "                    class_weight=class_weights_dict,\n",
    "                    callbacks=[early_stopping])\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(X_test_embeddings, y_test, verbose=2)\n",
    "print(f'\\nTest accuracy: {test_acc:.4f}')\n",
    "\n",
    "# Predict the labels for the test set\n",
    "y_pred = model.predict(X_test_embeddings)\n",
    "y_pred_classes = (y_pred > 0.5).astype(\"int32\")\n",
    "\n",
    "# Generate the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred_classes)\n",
    "\n",
    "# Visualize the confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Class 0', 'Class 1'], yticklabels=['Class 0', 'Class 1'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_test, y_pred_classes, target_names=['Class 0', 'Class 1']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85730ff7",
   "metadata": {},
   "source": [
    "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
    "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
    "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
    "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
    "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
    "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
    "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
    "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
    "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d47e0a7",
   "metadata": {},
   "source": [
    "Epoch 1/5\n",
    "1102/1102 [==============================] - 443s 390ms/step - loss: 0.5381 - accuracy: 0.7320 - val_loss: 0.4959 - val_accuracy: 0.7947\n",
    "Epoch 2/5\n",
    "1102/1102 [==============================] - 424s 385ms/step - loss: 0.4686 - accuracy: 0.7822 - val_loss: 0.3700 - val_accuracy: 0.8142\n",
    "Epoch 3/5\n",
    "1102/1102 [==============================] - 426s 386ms/step - loss: 0.4434 - accuracy: 0.7869 - val_loss: 0.4812 - val_accuracy: 0.7661\n",
    "Epoch 4/5\n",
    "1102/1102 [==============================] - 426s 386ms/step - loss: 0.4171 - accuracy: 0.8071 - val_loss: 0.4239 - val_accuracy: 0.8169\n",
    "Epoch 5/5\n",
    "1102/1102 [==============================] - 427s 388ms/step - loss: 0.3905 - accuracy: 0.8200 - val_loss: 0.3814 - val_accuracy: 0.8373\n",
    "138/138 - 7s - loss: 0.3700 - accuracy: 0.8142 - 7s/epoch - 48ms/step\n",
    "\n",
    "Test accuracy: 0.8142014741897583\n",
    "138/138 [==============================] - 8s 51ms/step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168bfc73",
   "metadata": {},
   "source": [
    "precision    recall  f1-score   support\n",
    "\n",
    "     Class 0       0.96      0.82      0.89      3874\n",
    "     Class 1       0.37      0.78      0.51       534\n",
    "\n",
    "    accuracy                           0.81      4408\n",
    "   macro avg       0.67      0.80      0.70      4408\n",
    "weighted avg       0.89      0.81      0.84      4408\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c41c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (confusion_matrix, classification_report, accuracy_score,\n",
    "                             recall_score, precision_score, f1_score, roc_auc_score,\n",
    "                             roc_curve, auc)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred_classes)\n",
    "recall = recall_score(y_test, y_pred_classes)\n",
    "precision = precision_score(y_test, y_pred_classes)\n",
    "f1 = f1_score(y_test, y_pred_classes)\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'Precision: {precision}')\n",
    "print(f'F1 Score: {f1}')\n",
    "print(f'ROC AUC Score: {roc_auc}')\n",
    "\n",
    "# Compute ROC curve\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred)\n",
    "roc_auc_value = auc(fpr, tpr)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='blue', lw=2, label=f'ROC curve (area = {roc_auc_value:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC)')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68c92e5",
   "metadata": {},
   "source": [
    "Accuracy: 0.8142014519056261\n",
    "Recall: 0.7846441947565543\n",
    "Precision: 0.37310774710596617\n",
    "F1 Score: 0.5057332528666264\n",
    "ROC AUC Score: 0.8777224616622099\n",
    "Among all other dl models, the BERT with LSTM model is giving the best result with a good accuracy and a notable recall of 78%.The metric that iam considering is recall(i.e. Recall measures the proportion of true positive instances correctly identified by the model among all actual positive instances.) As there is an improvement in the metric that Iam considering that is Recall which is improved from 56% to 78% and The ROC AUC Score was also showing betterment than the finalized benchmark of the Machine Learning Model. Based on these, I Finalized BERT with LSTM model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
